{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89374299-b30f-4a1d-9b65-56fd5fad56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=\"2\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import HTML\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc75a23-7760-437f-ac57-709b65246c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproducibility.\n",
    "SEED = 42\n",
    "keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# DATA\n",
    "BUFFER_SIZE = 300\n",
    "BATCH_SIZE = 64\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (15, 120, 160, 3)\n",
    "TIME_LEN = INPUT_SHAPE[0]\n",
    "OUTPUT_SHAPE = (120, 160, 3)\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 5e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# PRETRAINING\n",
    "EPOCHS = 500\n",
    "\n",
    "# AUGMENTATION\n",
    "IMAGE_SIZE = 48  # We will resize input images to this size.\n",
    "PATCH_SIZE = 6  # Size of the patches to be extracted from the input images.\n",
    "CROP_SIZE = 100\n",
    "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
    "MASK_PROPORTION = 0.75  # We have found 75% masking to give us the best results.\n",
    "\n",
    "# ENCODER and DECODER\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "ENC_PROJECTION_DIM = 128\n",
    "DEC_PROJECTION_DIM = 64\n",
    "ENC_NUM_HEADS = 4\n",
    "ENC_LAYERS = 8\n",
    "DEC_NUM_HEADS = 4\n",
    "DEC_LAYERS = (\n",
    "    4  # The decoder is lightweight but should be reasonably deep for reconstruction.\n",
    ")\n",
    "ENC_TRANSFORMER_UNITS = [\n",
    "    ENC_PROJECTION_DIM * 2,\n",
    "    ENC_PROJECTION_DIM,\n",
    "]  # Size of the transformer layers.\n",
    "DEC_TRANSFORMER_UNITS = [\n",
    "    DEC_PROJECTION_DIM * 2,\n",
    "    DEC_PROJECTION_DIM,\n",
    "]\n",
    "\n",
    "\n",
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = False\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print('Accelerated Linear Algebra enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa177011-9315-454e-9061-849a4c66438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Returns a Dataset for reading from a SageMaker PipeMode channel.\"\"\"\n",
    "features = {\n",
    "    'video': tf.io.FixedLenFeature([], tf.string),\n",
    "    'frame': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def parse(record):\n",
    "\n",
    "    parsed = tf.io.parse_single_example(\n",
    "        serialized=record,\n",
    "        features=features\n",
    "    )\n",
    "    video_raw = parsed['video']\n",
    "    video_raw = tf.io.decode_raw(video_raw, tf.uint8)\n",
    "    video_raw = tf.cast(video_raw, tf.float32)\n",
    "\n",
    "    label = parsed['label']\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    video_raw = tf.reshape(video_raw, INPUT_SHAPE[:3] + (1,))\n",
    "    video_raw = tf.concat([video_raw, video_raw, video_raw], axis=-1)\n",
    "\n",
    "    return video_raw, label\n",
    "\n",
    "\n",
    "def left_right_flip(video):\n",
    "    '''\n",
    "    Performs tf.image.flip_left_right on entire list of video frames.\n",
    "    Work around since the random selection must be consistent for entire video\n",
    "    :param video: Tensor constaining video frames (N,H,W,3)\n",
    "    :return: video: Tensor constaining video frames left-right flipped (N,H,W,3)\n",
    "    '''\n",
    "    video_list = tf.unstack(video, axis=1)\n",
    "    for i in range(len(video_list)):\n",
    "        video_list[i] = tf.image.flip_left_right(video_list[i])\n",
    "    video = tf.stack(video_list, axis=1)\n",
    "    return video\n",
    "\n",
    "\n",
    "def random_crop(video, size):\n",
    "    # (T, H, W, 3)\n",
    "    shape = tf.shape(video)\n",
    "    size = tf.convert_to_tensor(size, dtype=shape.dtype)\n",
    "    h_diff = shape[2] - size[1]\n",
    "    w_diff = shape[3] - size[0]\n",
    "\n",
    "    dtype = shape.dtype\n",
    "    rands = tf.random.uniform(shape=[2], minval=0, maxval=dtype.max, dtype=dtype)\n",
    "    h_start = tf.cast(rands[0] % (h_diff + 1), dtype)\n",
    "    w_start = tf.cast(rands[1] % (w_diff + 1), dtype)\n",
    "    size = tf.cast(size, tf.int32)\n",
    "    video_list = tf.unstack(video, axis=1)\n",
    "    for i in range(len(video_list)):\n",
    "        video_list[i] = tf.image.crop_to_bounding_box(\n",
    "            video_list[i],\n",
    "            h_start, w_start,\n",
    "            size[1], size[0]\n",
    "        )\n",
    "    video = tf.stack(video_list, axis=1)\n",
    "\n",
    "    return video\n",
    "\n",
    "\n",
    "def resize(video, size):\n",
    "    video_list = tf.unstack(video, axis=1)\n",
    "    for i in range(len(video_list)):\n",
    "        video_list[i] = tf.image.resize(\n",
    "            video_list[i],\n",
    "            size\n",
    "        )\n",
    "    video = tf.stack(video_list, axis=1)\n",
    "    return video\n",
    "\n",
    "\n",
    "class TrainingPreprocessing(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        crop_size=(CROP_SIZE, CROP_SIZE),\n",
    "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.crop_size = crop_size\n",
    "        self.image_size = image_size\n",
    "        super(TrainingPreprocessing, self).__init__()\n",
    "\n",
    "    def call(self, data):\n",
    "        video = data\n",
    "        video = random_crop(video, self.crop_size)\n",
    "        video = resize(video, self.image_size)\n",
    "        sample = tf.random.uniform(shape=[], minval=0, maxval=1, dtype=tf.float32)\n",
    "        option = tf.less(sample, 0.5)\n",
    "        video= tf.cond(\n",
    "            option,\n",
    "            lambda: left_right_flip(video),\n",
    "            lambda: video\n",
    "        )\n",
    "        video = tf.cast(video, tf.float32) * (1 / 255.)\n",
    "        return video\n",
    "\n",
    "\n",
    "class TestingPreprocessing(tf.keras.layers.Layer):\n",
    "    def __init__(self, size=(IMAGE_SIZE, IMAGE_SIZE), **kwargs):\n",
    "        self.size = size\n",
    "        super(TestingPreprocessing, self).__init__()\n",
    "\n",
    "    def call(self, data):\n",
    "        video = data\n",
    "        video = resize(video, self.size)\n",
    "        video = tf.cast(video, tf.float32) * (1 / 255.)\n",
    "        return video\n",
    "\n",
    "\n",
    "def get_train_augmentation_model(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    crop_size=(CROP_SIZE, CROP_SIZE),\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "):\n",
    "    inputs = keras.Input(\n",
    "        shape=input_shape,\n",
    "        name=\"Original Video\"\n",
    "    )\n",
    "    aug = TrainingPreprocessing(\n",
    "        crop_size=crop_size,\n",
    "        image_size=image_size\n",
    "    )(inputs)\n",
    "    return keras.Model(inputs=[inputs], outputs=[aug], name=\"train_data_augmentation\")\n",
    "\n",
    "\n",
    "def get_test_augmentation_model(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "):\n",
    "    inputs = keras.Input(\n",
    "        shape=input_shape,\n",
    "        name=\"Original Video\"\n",
    "    )\n",
    "    aug = TestingPreprocessing(\n",
    "        image_size=image_size\n",
    "    )(inputs)\n",
    "    return keras.Model(inputs=[inputs], outputs=[aug], name=\"test_data_augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1256a1-c2dc-4437-a5fb-42c6b4ea5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size=PATCH_SIZE, time_len=TIME_LEN, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "        self.time_len = time_len\n",
    "        self.resize = layers.Reshape((-1, patch_size * patch_size * 3))\n",
    "\n",
    "    def call(self, data):\n",
    "        # video, label = data\n",
    "        video = data\n",
    "        # Create patches from the input images\n",
    "        video_list = tf.unstack(video, axis=1)\n",
    "        for i in range(len(video_list)):\n",
    "            patches = tf.image.extract_patches(\n",
    "                images=video_list[i],\n",
    "                sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "                strides=[1, self.patch_size, self.patch_size, 1],\n",
    "                rates=[1, 1, 1, 1],\n",
    "                padding=\"VALID\",\n",
    "            )\n",
    "\n",
    "            # Reshape the patches to (batch, num_patches, patch_area) and return it.\n",
    "            video_list[i] = self.resize(patches)\n",
    "        video = tf.stack(video_list, axis=1)\n",
    "        # return video, label\n",
    "        return video\n",
    "\n",
    "    def show_patched_image(self, video, patches):\n",
    "        # This is a utility function which accepts a batch of images and its\n",
    "        # corresponding patches and help visualize one image and its patches\n",
    "        # side by side.\n",
    "        idx = np.random.choice(patches.shape[0])\n",
    "        n = int(np.sqrt(patches.shape[-2]))\n",
    "        print(f\"Index selected: {idx}.\")\n",
    "\n",
    "        fig = plt.figure()\n",
    "        gs = gridspec.GridSpec(n, 2 * n, figure=fig, hspace=0.08, wspace=0.1)\n",
    "        ax = fig.add_subplot(gs[:n, n: 2*n])\n",
    "        big_im = ax.imshow(video[idx, 0, ...])\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        grid = list(product(range(n), range(n)))\n",
    "        patch_list = []\n",
    "        for i in range(patches.shape[-2]):\n",
    "            ax = fig.add_subplot(gs[grid[i][0], grid[i][1]])\n",
    "            patch_img = tf.reshape(\n",
    "                patches[idx, 0, i, :],\n",
    "                (self.patch_size, self.patch_size, 3)\n",
    "            )\n",
    "            im = ax.imshow(patch_img)\n",
    "            patch_list.append(im)\n",
    "            ax.set_axis_off()\n",
    "        plt.close()\n",
    "        def init():\n",
    "            big_im.set_data(video[idx,0,...])\n",
    "            for i, im in enumerate(patch_list):\n",
    "                patch_img = tf.reshape(\n",
    "                    patches[idx, 0, i, :],\n",
    "                    (self.patch_size, self.patch_size, 3)\n",
    "                )\n",
    "                im.set_data(patch_img)\n",
    "        def animate(j):\n",
    "            big_im.set_data(video[idx,j,...])\n",
    "            for i, im in enumerate(patch_list):\n",
    "                patch_img = tf.reshape(\n",
    "                    patches[idx, j, i, :],\n",
    "                    (self.patch_size, self.patch_size, 3)\n",
    "                )\n",
    "                im.set_data(patch_img)\n",
    "        anim = animation.FuncAnimation(\n",
    "            fig,\n",
    "            animate,\n",
    "            init_func=init,\n",
    "            frames=video.shape[1],\n",
    "            interval=50\n",
    "        )\n",
    "        return anim, idx\n",
    "\n",
    "    # taken from https://stackoverflow.com/a/58082878/10319735\n",
    "    def reconstruct_from_patch(self, patch):\n",
    "        # This utility function takes patches from a *single* image and\n",
    "        # reconstructs it back into the image. This is useful for the train\n",
    "        # monitor callback.\n",
    "        num_patches = patch.shape[-2]\n",
    "        n = int(np.sqrt(num_patches))\n",
    "        patch = tf.reshape(patch, (self.time_len, num_patches, self.patch_size, self.patch_size, 3))\n",
    "        video = []\n",
    "        for i in range(self.time_len):\n",
    "            rows = tf.split(patch[i], n, axis=0)\n",
    "            rows = [tf.concat(tf.unstack(x), axis=1) for x in rows]\n",
    "            reconstructed = tf.concat(rows, axis=0)\n",
    "            video.append(reconstructed)\n",
    "        return tf.stack(video, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6af3e9d-1803-4203-be3f-0028409423ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        time_len=TIME_LEN,\n",
    "        projection_dim=ENC_PROJECTION_DIM,\n",
    "        mask_proportion=MASK_PROPORTION,\n",
    "        downstream=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "        self.time_len = time_len\n",
    "        self.projection_dim = projection_dim\n",
    "        self.mask_proportion = mask_proportion\n",
    "        self.downstream = downstream\n",
    "\n",
    "        # This is a trainable mask token initialized randomly from a normal\n",
    "        # distribution.\n",
    "        self.mask_token = tf.Variable(\n",
    "            tf.random.normal([self.time_len, 1, patch_size * patch_size * 3]), trainable=True\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        (_, self.num_frames, self.num_patches, self.patch_area) = input_shape\n",
    "\n",
    "        # Create the projection layer for the patches.\n",
    "        self.projection = layers.GRU(units=self.projection_dim)\n",
    "        # Create the positional embedding layer.\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=self.num_patches, output_dim=self.projection_dim\n",
    "        )\n",
    "\n",
    "        # Number of patches that will be masked.\n",
    "        self.num_mask = int(self.mask_proportion * self.num_patches)\n",
    "\n",
    "    def call(self, patches):\n",
    "        # patches: (B, T, N, ps*ps)\n",
    "        # Get the positional embeddings.\n",
    "        batch_size = tf.shape(patches)[0]\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        pos_embeddings = self.position_embedding(positions[tf.newaxis, ...])\n",
    "        pos_embeddings = tf.tile(\n",
    "            pos_embeddings, [batch_size, 1, 1]\n",
    "        )  # (B, num_patches, projection_dim)\n",
    "\n",
    "        # Embed the patches. (GRU)\n",
    "        projection = tf.unstack(patches, axis=-2)\n",
    "        for i in range(len(projection)):\n",
    "            projection[i] = self.projection(projection[i])\n",
    "        # (B, num_patches, projection_dim)\n",
    "        projection = tf.stack(projection, axis=1)\n",
    "\n",
    "        patch_embeddings = (\n",
    "            projection + pos_embeddings\n",
    "        )  # (B, num_patches, projection_dim)\n",
    "\n",
    "        if self.downstream:\n",
    "            return patch_embeddings\n",
    "        else:\n",
    "            mask_indices, unmask_indices = self.get_random_indices(batch_size)\n",
    "            # The encoder input is the unmasked patch embeddings. Here we gather\n",
    "            # all the patches that should be unmasked.\n",
    "            unmasked_embeddings = tf.gather(\n",
    "                patch_embeddings, unmask_indices, axis=1, batch_dims=1\n",
    "            )  # (B, unmask_numbers, projection_dim)\n",
    "\n",
    "            # Get the unmasked and masked position embeddings. We will need them\n",
    "            # for the decoder.\n",
    "            unmasked_positions = tf.gather(\n",
    "                pos_embeddings, unmask_indices, axis=1, batch_dims=1\n",
    "            )  # (B, unmask_numbers, projection_dim)\n",
    "            masked_positions = tf.gather(\n",
    "                pos_embeddings, mask_indices, axis=1, batch_dims=1\n",
    "            )  # (B, mask_numbers, projection_dim)\n",
    "\n",
    "            # Repeat the mask token number of mask times.\n",
    "            # Mask tokens replace the masks of the image.\n",
    "            # mask_tokens: (T, ps*ps)\n",
    "            mask_tokens = tf.repeat(self.mask_token, repeats=self.num_mask, axis=1)\n",
    "            # mask_tokens = (mask_numbers, projection_dim) \n",
    "            mask_tokens = tf.repeat(\n",
    "                mask_tokens[tf.newaxis, ...], repeats=batch_size, axis=0\n",
    "            )\n",
    "            # Embed the tokens (GRU)\n",
    "            mask_tokens = tf.unstack(mask_tokens, axis=-2)\n",
    "            for i in range(len(mask_tokens)):\n",
    "                mask_tokens[i] = self.projection(mask_tokens[i])\n",
    "            # (B, num_patches, projection_dim)\n",
    "            mask_tokens = tf.stack(mask_tokens, axis=1)\n",
    "            # Get the masked embeddings for the tokens.\n",
    "            masked_embeddings = mask_tokens + masked_positions\n",
    "            return (\n",
    "                unmasked_embeddings,  # Input to the encoder.\n",
    "                masked_embeddings,  # First part of input to the decoder.\n",
    "                unmasked_positions,  # Added to the encoder outputs.\n",
    "                mask_indices,  # The indices that were masked.\n",
    "                unmask_indices,  # The indices that were unmaksed.\n",
    "            )\n",
    "\n",
    "    def get_random_indices(self, batch_size):\n",
    "        # Create random indices from a uniform distribution and then split\n",
    "        # it into mask and unmask indices.\n",
    "        rand_indices = tf.argsort(\n",
    "            tf.random.uniform(shape=(batch_size, self.num_patches)), axis=-1\n",
    "        )\n",
    "        mask_indices = rand_indices[:, : self.num_mask]\n",
    "        unmask_indices = rand_indices[:, self.num_mask :]\n",
    "        return mask_indices, unmask_indices\n",
    "\n",
    "    def generate_masked_image(self, patches, unmask_indices):\n",
    "        # Choose a random patch and it corresponding unmask index.\n",
    "        idx = np.random.choice(patches.shape[0])\n",
    "        patch = patches[idx]\n",
    "        unmask_index = unmask_indices[idx]\n",
    "\n",
    "        # Build a numpy array of same shape as patch.\n",
    "        new_patch = np.zeros_like(patch)\n",
    "\n",
    "        # Iterate of the new_patch and plug the unmasked patches.\n",
    "        for i in range(unmask_index.shape[0]):\n",
    "            new_patch[:, unmask_index[i], ...] = patch[:, unmask_index[i], ...]\n",
    "        return new_patch, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19b9e52-11fa-4e43-9036-a886f6730b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, dropout_rate, hidden_units):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_encoder(\n",
    "    num_heads=ENC_NUM_HEADS,\n",
    "    num_layers=ENC_LAYERS,\n",
    "    projection_dim=ENC_PROJECTION_DIM,\n",
    "    transformer_units=ENC_TRANSFORMER_UNITS,\n",
    "    epsilon=LAYER_NORM_EPS,\n",
    "):\n",
    "    inputs = layers.Input(\n",
    "        (None, projection_dim)\n",
    "    )\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=epsilon)(x)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=epsilon)(x2)\n",
    "\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add()([x3, x2])\n",
    "\n",
    "    outputs = layers.LayerNormalization(epsilon=epsilon)(x)\n",
    "    return keras.Model(inputs, outputs, name=\"mae_encoder\")\n",
    "\n",
    "\n",
    "def create_decoder(\n",
    "    num_layers=DEC_LAYERS,\n",
    "    num_heads=DEC_NUM_HEADS,\n",
    "    num_patches=NUM_PATCHES,\n",
    "    enc_projection_dim=ENC_PROJECTION_DIM,\n",
    "    dec_projection_dim=DEC_PROJECTION_DIM,\n",
    "    epsilon=LAYER_NORM_EPS,\n",
    "    transformer_units=DEC_TRANSFORMER_UNITS,\n",
    "    image_size=IMAGE_SIZE\n",
    "):\n",
    "    inputs = layers.Input(\n",
    "        (num_patches, enc_projection_dim)\n",
    "    )\n",
    "    x = layers.Dense(dec_projection_dim)(inputs)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=epsilon)(x)\n",
    "\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=dec_projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=epsilon)(x2)\n",
    "\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add()([x3, x2])\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=epsilon)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    pre_final = layers.Dense(units=image_size * image_size * 3, activation='sigmoid')(x) # tanh sigmoid\n",
    "    outputs = layers.Reshape((image_size, image_size, 3))(pre_final)\n",
    "\n",
    "    return keras.Model(inputs, outputs, name=\"mae_decoder\")\n",
    "\n",
    "class MaskedAutoencoder(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        output_shape=OUTPUT_SHAPE,\n",
    "        crop_size=(CROP_SIZE, CROP_SIZE),\n",
    "        image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        patch_size=PATCH_SIZE,\n",
    "        num_patches=NUM_PATCHES,\n",
    "        time_len=TIME_LEN,\n",
    "        mask_proportion=MASK_PROPORTION,\n",
    "        enc_projection_dim=ENC_PROJECTION_DIM,\n",
    "        enc_transformer_units=ENC_TRANSFORMER_UNITS,\n",
    "        num_enc_heads=ENC_NUM_HEADS,\n",
    "        num_enc_layers=ENC_LAYERS,\n",
    "        num_dec_layers=DEC_LAYERS,\n",
    "        num_dec_heads=DEC_NUM_HEADS,\n",
    "        dec_projection_dim=DEC_PROJECTION_DIM,\n",
    "        dec_transformer_units=DEC_TRANSFORMER_UNITS,\n",
    "        epsilon=LAYER_NORM_EPS,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.train_augmentation_model = get_train_augmentation_model(\n",
    "            input_shape=input_shape,\n",
    "            crop_size=crop_size,\n",
    "            image_size=image_size,\n",
    "        )\n",
    "        self.test_augmentation_model = get_test_augmentation_model(\n",
    "            input_shape=input_shape,\n",
    "            image_size=image_size,\n",
    "        )\n",
    "        self.patch_layer = Patches(\n",
    "            patch_size=patch_size,\n",
    "            time_len=time_len,\n",
    "        )\n",
    "        self.patch_encoder = PatchEncoder(\n",
    "            patch_size=patch_size,\n",
    "            time_len=time_len,\n",
    "            projection_dim=enc_projection_dim,\n",
    "            mask_proportion=mask_proportion,\n",
    "            downstream=False\n",
    "        )\n",
    "        self.encoder = create_encoder(\n",
    "            num_heads=num_enc_heads,\n",
    "            num_layers=num_enc_layers,\n",
    "            projection_dim=enc_projection_dim,\n",
    "            transformer_units=enc_transformer_units,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "        self.decoder = create_decoder(\n",
    "            num_layers=num_dec_layers,\n",
    "            num_heads=num_dec_heads,\n",
    "            num_patches=num_patches,\n",
    "            enc_projection_dim=enc_projection_dim,\n",
    "            dec_projection_dim=dec_projection_dim,\n",
    "            epsilon=epsilon,\n",
    "            transformer_units=dec_transformer_units,\n",
    "            image_size=image_size[0],\n",
    "        )\n",
    "        self.resize = layers.Reshape((-1, patch_size * patch_size * 3))\n",
    "        self.mse_loss = tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Encode the patches.\n",
    "        (\n",
    "            unmasked_embeddings,\n",
    "            masked_embeddings,\n",
    "            unmasked_positions,\n",
    "            mask_indices,\n",
    "            unmask_indices,\n",
    "        ) = self.patch_encoder(inputs)\n",
    "\n",
    "        # Pass the unmaksed patche to the encoder.\n",
    "        encoder_outputs = self.encoder(unmasked_embeddings)\n",
    "\n",
    "        # Create the decoder inputs.\n",
    "        encoder_outputs = encoder_outputs + unmasked_positions\n",
    "        decoder_inputs = tf.concat([encoder_outputs, masked_embeddings], axis=1)\n",
    "\n",
    "        # Decode the inputs.\n",
    "        decoder_outputs = self.decoder(decoder_inputs)\n",
    "        return decoder_outputs\n",
    "\n",
    "    def train_step(self, data):\n",
    "        videos, next_frames = data\n",
    "        aug_videos, next_frame = self.train_augmentation_model([videos, next_frames])\n",
    "        # Patch the augmented images.\n",
    "        vid_patches, frame_patches = self.patch_layer([aug_videos, next_frame])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            decoder_outputs = self(vid_patches)\n",
    "            decoder_patches = tf.image.extract_patches(\n",
    "                images=decoder_outputs,\n",
    "                sizes=[1, self.patch_layer.patch_size, self.patch_layer.patch_size, 1],\n",
    "                strides=[1, self.patch_layer.patch_size, self.patch_layer.patch_size, 1],\n",
    "                rates=[1, 1, 1, 1],\n",
    "                padding=\"VALID\",\n",
    "            )\n",
    "            # Calculate loss on all patches.\n",
    "            loss_output = self.resize(decoder_patches)\n",
    "            loss_patch = self.resize(frame_patches)\n",
    "            # Calculate loss on masked patches.\n",
    "            # loss_patch = tf.gather(\n",
    "            #     loss_patch,\n",
    "            #     mask_indices,\n",
    "            #     axis=1,\n",
    "            #     batch_dims=1\n",
    "            # )\n",
    "            # loss_output = tf.gather(\n",
    "            #     loss_output,\n",
    "            #     mask_indices,\n",
    "            #     axis=1,\n",
    "            #     batch_dims=1\n",
    "            # )\n",
    "            # Compute the total loss.\n",
    "            # Calculate loss on masked patches\n",
    "            # total_loss = self.compiled_loss(loss_patch, loss_output)\n",
    "            # # Calculate loss on all outputs\n",
    "            total_loss = self.mse_loss(frame_patches, decoder_patches)\n",
    "        # Apply gradients.\n",
    "        train_vars = [\n",
    "            self.train_augmentation_model.trainable_variables,\n",
    "            self.patch_layer.trainable_variables,\n",
    "            self.patch_encoder.trainable_variables,\n",
    "            self.encoder.trainable_variables,\n",
    "            self.decoder.trainable_variables,\n",
    "        ]\n",
    "        grads = tape.gradient(total_loss, train_vars)\n",
    "        # import pdb\n",
    "        # pdb.set_trace()\n",
    "        tv_list = []\n",
    "        for (grad, var) in zip(grads, train_vars):\n",
    "            for g, v in zip(grad, var):\n",
    "                tv_list.append((g, v))\n",
    "        self.optimizer.apply_gradients(tv_list)\n",
    "\n",
    "        # Report progress.\n",
    "\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.mae_metric.update_state(loss_patch, loss_output)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        videos, next_frames = data\n",
    "        aug_videos, next_frame = self.test_augmentation_model([videos, next_frames])\n",
    "        vid_patches, frame_patches = self.patch_layer([aug_videos, next_frame])\n",
    "\n",
    "        decoder_outputs = self(vid_patches)\n",
    "        decoder_patches = tf.image.extract_patches(\n",
    "            images=decoder_outputs,\n",
    "            sizes=[1, self.patch_layer.patch_size, self.patch_layer.patch_size, 1],\n",
    "            strides=[1, self.patch_layer.patch_size, self.patch_layer.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        # Calculate loss on all patches.\n",
    "        loss_output = self.resize(decoder_patches)\n",
    "        loss_patch = self.resize(frame_patches)\n",
    "        # Calculate loss on masked patches.\n",
    "        # loss_patch = tf.gather(\n",
    "        #     loss_patch,\n",
    "        #     mask_indices,\n",
    "        #     axis=1,\n",
    "        #     batch_dims=1\n",
    "        # )\n",
    "        # loss_output = tf.gather(\n",
    "        #     loss_output,\n",
    "        #     mask_indices,\n",
    "        #     axis=1,\n",
    "        #     batch_dims=1\n",
    "        # )\n",
    "        # Compute the total loss.\n",
    "        # Calculate loss on masked patches\n",
    "        # total_loss = self.compiled_loss(loss_patch, loss_output)\n",
    "        # # Calculate loss on all outputs\n",
    "        total_loss = self.mse_loss(frame_patches, decoder_patches)\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.mae_metric.update_state(loss_patch, loss_output)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [self.loss_tracker, self.mae_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b31e2d-6f6c-49b6-8966-14e36dc49b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_model = MaskedAutoencoder(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    output_shape=OUTPUT_SHAPE,\n",
    "    crop_size=(CROP_SIZE, CROP_SIZE),\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    patch_size=PATCH_SIZE,\n",
    "    num_patches=NUM_PATCHES,\n",
    "    time_len=TIME_LEN,\n",
    "    mask_proportion=MASK_PROPORTION,\n",
    "    enc_projection_dim=ENC_PROJECTION_DIM,\n",
    "    enc_transformer_units=ENC_TRANSFORMER_UNITS,\n",
    "    num_enc_heads=ENC_NUM_HEADS,\n",
    "    num_enc_layers=ENC_LAYERS,\n",
    "    num_dec_layers=DEC_LAYERS,\n",
    "    num_dec_heads=DEC_NUM_HEADS,\n",
    "    dec_projection_dim=DEC_PROJECTION_DIM,\n",
    "    dec_transformer_units=DEC_TRANSFORMER_UNITS,\n",
    "    epsilon=LAYER_NORM_EPS,\n",
    ")\n",
    "mae_model.load_weights('models/KTH/')\n",
    "\n",
    "# Extract the patchers.\n",
    "patch_layer = mae_model.patch_layer\n",
    "patch_encoder = mae_model.patch_encoder\n",
    "patch_encoder.downstream = True  # Swtich the downstream flag to True.\n",
    "\n",
    "# Extract the encoder.\n",
    "encoder = mae_model.encoder\n",
    "decoder = mae_model.decoder\n",
    "\n",
    "# Pack as a model.\n",
    "downstream_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((15, IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "        patch_layer,\n",
    "        patch_encoder,\n",
    "        encoder,\n",
    "        decoder\n",
    "    ],\n",
    "    name=\"linear_probe_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc7e82c2-d038-4fa8-a6bd-b394ee8c7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmentation_model = mae_model.train_augmentation_model\n",
    "test_augmentation_model = mae_model.test_augmentation_model\n",
    "\n",
    "\n",
    "files = tf.data.Dataset.list_files(\"datasets/KTH_tfrecords/training/*.tfrecord\")\n",
    "train_ds = files.interleave(\n",
    "    lambda x: tf.data.TFRecordDataset(x).prefetch(100),\n",
    "    cycle_length=8\n",
    ")\n",
    "train_ds = train_ds.map(parse, num_parallel_calls=AUTO)\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(\n",
    "            lambda x, y: (test_augmentation_model(x), y), num_parallel_calls=AUTO\n",
    "        )\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n",
    "files = tf.data.Dataset.list_files(\"datasets/KTH_tfrecords/validation/*.tfrecord\")\n",
    "val_ds = files.interleave(\n",
    "    lambda x: tf.data.TFRecordDataset(x).prefetch(100),\n",
    "    cycle_length=8\n",
    ")\n",
    "val_ds = val_ds.map(parse, num_parallel_calls=AUTO)\n",
    "val_ds = val_ds.repeat()\n",
    "val_ds = (\n",
    "    val_ds\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(\n",
    "            lambda x, y: (test_augmentation_model(x) ,y), num_parallel_calls=AUTO\n",
    "        )\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a864e027-7bfe-40bc-b507-3102f1b4cfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos: (15, 48, 48, 3)\n",
      "Next frame: ()\n"
     ]
    }
   ],
   "source": [
    "videos, labels = next(iter(train_ds))\n",
    "print(f\"Videos: {videos[0].get_shape()}\")\n",
    "print(f\"Next frame: {labels[0].get_shape()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83df4b99-c2f7-444a-92f4-48eae872cac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAABaWG1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9OSBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MTAgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAA3dZYiE\n",
       "ABH//veIHzLLafk613IR560urR9Q7kZxXqS9/iAAAAMAFpyZQ/thx05aw0AAQomzSj/s4ZcQBkHG\n",
       "BJea/UcT0Xnf6C92cFo3x+H9L5jlyaomc1s2uugGkZjE4oESmO8mX+radyDOHzrErdiIqRWcvADK\n",
       "4uLo3YD6t9/oejO4wjo/L8aqU8MpndNtXX1DKLhHDDRrvSSWsPftWL1LG7F4Eg5p9Ty8kGs2f+aT\n",
       "/ZzFfLHzQCf2KtMYA/ghJZp9EjBqn8W0khaoXQmvEw80xgx4CX26rXRjmOEXlLR+d8hcDNJLy3j9\n",
       "bIaq7drJV4jxLsOqBfR+ZUEJLYDghhyTX0qXSIg1G905lKlQYPKkpLfh/X6t3rdjy/tnH/MraN4a\n",
       "2lAvHqM9OzsHtP9KpHkjktcZjrG8AaM16+YHVklqChZJbpAjAouZnAJK5yUVPVF2Gk9fBeIftrnX\n",
       "/AH7a3KVsVmaZZynYeq0TG4XRebrv63WLKaNCEM+euBDGr8/2xO2TR7Y9IooMpYrH+pJCk5bfPQu\n",
       "ee3dwrFfHiQYGstMv5Tcg1FPdmVYeGbtDJ/6u3jZqq3bxFH001k4tPzlMwHMRi+/FzPDKq4s9BJv\n",
       "fbHrknpMY3qv0EQAJCHAT0rhhA0lx7qjOW6QgHJu9NmVKAkSxHTCVSXmWK9lg29CesufGqvF8Yz0\n",
       "ziiGlikPXi/Ct252UTdNOgBB0m50JZrePobqTxXX8p+Kal0aWWhChLqbWedozE8wefdBMMzUEfeb\n",
       "Uf3jPPthsfC8shqRtjZ+agil7xB5bpZOePhgrxdAaDwIgyDZW8NKan3GzaVAdpZ/D0rzevM4UFB6\n",
       "VCVE5zc3Wnsge70rVBAFch6+1diQOtYWw8c9tKCuZcFs2rNV+W1CkM8IK2jYQWX7lYVxCBstR4jx\n",
       "teQDFYRz4nH3sESeZjqU7aTcq6dOBJfXMK+tZW85FkKXjy62nfdlTK3CueWnYVezWeZgIOFz7CVU\n",
       "QVk5vAvWCwOjw0A/jsbG4kJU2A1HiOyxVRyqZInyk32ZNwoAFO/LaYghahxbrVoUbXQRl5t93by+\n",
       "TJTlrbjiC4U4kas0akQU2ZO5sZhPv0VgsbBAKHFKxXnHUXZmVkMBg6LF1BhLWz+ouDtabztdpkbt\n",
       "Gl+7fyne7x5ykseVFa2MqN4+2/H/PuYzRIjd480QeZySL4HmIG2sKX3D8ZceRBl0hTWehLbBRqdr\n",
       "bbKZjDUQKydMdBWpIfxZWhG26v5jDViIqOFbBvviY/RKg55hUv+PJPoahfCnAgKraZO6q/cHiTSl\n",
       "JDiVng6IZ+KHRzObag7Jjd8wL4VyCOLylkrruG1Z04GCx8ElsaFKwU/9v2Ofhot4v6kiYxRDbRiV\n",
       "kJilx1NjOps27X1l51WvqRMkfvtoG8YMX30GSMsbCGrEiMRtgpr7O6txva4EoriwvKyfzYAEvSmq\n",
       "PUdcTD4BD/PZY1etn7eUlYR779kKviwnBsAzusyb+mozKNVUXw2O3sgGO/fKNflO4Co7IKdIsNgR\n",
       "csu82QhNnAJ+8NvIKPtgzWcGn1INqMzmUVu3r6O5jTVw8GOweCnM5qWXIGeeAYjLto0wuBz6V0be\n",
       "ZyZuls/WiB8JV+yF2tzA9y534Qy3n1Vc2FT6Tsxljj41fedEUY4FvaBETuyEWQVJ8O/RLJy8akRf\n",
       "s1S2q6BTUKIt/Uf5eL/z35Wq/5Ho788kVwQz9cw1cL6Aakt4zAywQzvGb6JYTWglDlU2d2guV2u5\n",
       "PQzRCfHmk1cvwtFl/a4rAgNCxim7oKiv1or8wkxNznIOWRun3nTjp5g3b81TaTf4Izh4RNrLXS5x\n",
       "Snb9h5SW55WMWaKcTzV6JKNh5ANbKz9v9VyvIqohAeokoWsQVVLlseHNsaSNXqgCHvn8lXWNHY0N\n",
       "vCFv0mw+Qso9MX8smD17aN+6Q0h5R7Zr+lUdsiAZfpCWA7nDT7EWGm4P87+6H/+8ytPxMP4aNus8\n",
       "Ae/bNMFmAcH6oEBUtB4XbpzokvMroEB1wgbJr6px0bPrM2RPWff3TE4OsZiZ6El1OghgCqnq+a+w\n",
       "TBNBIMENVMM8ZiJDUccYsM3YTu7/8Olf3f+WgmFuy4tYc8SZrD5qZEToFbJwUF6hXZSJycUUcLku\n",
       "6HlSkyUQw4ezT7XWQ5WiYZ3xn+jzCgUpvHd4UxkNr4t3MaXmPlSdLpRcEKSGtt99v2ZHZLrhluq5\n",
       "elB9MohAYIdE10B1f13rDaMDErmxtLlrAQuxrBwVCP+votsd9YO7EKwBE6zzpl/yU83wU/szuxPa\n",
       "Ws6Ygaj7dl9TZiXC0ZQU2ko9u3JPknN0UW0ZHzl84Krmou/wmqVZcloH+XDgtR2VjxcthrkxFFVU\n",
       "qXvMXsaN+WwmQOJoA0JI5ZNBX7k1NcrFM8OW6+1qX7ZR10JCksS05RAHTz3Gs4Fe3FkzmNGR8WtM\n",
       "vLV190DHCWu/vB9z6qsG9hA0mGqpvtnIEX+9JPDdcHoIPCy3Uy/mCtu2Ke8WzS0IoywRdT9Xshp6\n",
       "hO1dSsL9uS9Px5+/jUwleWTfVBhiLKjMVso1/9niHd4WD6jMgmL2fKo5qsHoC89qdtX4bLXvRrNy\n",
       "IUScMnCkCNJYYsIJSizav53bA4bFj8CgHwYBJpOuooAsmttRNiZbea18p0yYjNyOmJeBJG/qXoZC\n",
       "UZUsdwcY8UNtetcLXNxhp0HhQ7qXQxX5S04gNJxEZhA2icIit5as0g4opz3A8INqAji6l6cSODjW\n",
       "zbC6g88fh4k/fclQtYA30oI7fsPluEep5oCAyPPR/ARbEmyshp1xhHY0GlhECkFuW20IxCHpxnc+\n",
       "AyQN0QF+w5ejlWgGAVRGWEoozs50txr/aNQKStJotyHNXRPl2XA3yyaal7Lqlv7tU9cRoWu+qI7d\n",
       "l8Ca7etAPgTxSJ9cd+2luRTgTLmhcgQwV26JqFPQb/+6NhxCy+18AEMgaLxteCSngPrrYBDMTxFA\n",
       "OPwvwZ6cJoSD68WnigIqXPDMyCKu/gXPGk7riSQTJPXXupzltCykINPvVFSD8EXA+0WB3sCeeyG+\n",
       "Q9FNte3qZ8gA/RlFEHDvKh81ugShPwRbxVB40MGJ71AePwePWTyDcCOelZLNebPYCwzEHXv52UFk\n",
       "BFqXW/IN3mTPvYNeIckdfIxhmCe42B5QvHEUUZAI7qjFZOopYHs8GJk+qHF/kDuGgTI8qxIZsOYY\n",
       "+hTdOu9bcDXXMJsPnOeNyvDNWXc/fJ+g6QKbwix8ERuIIO6uSafZ8IH7xs1dU4DizNAWwUpGM1vy\n",
       "QsIjdz0Amc7Wuh4n0eEbEgCxrEWTXIkqyFA08hjQxjV+TyROcI82ZKdakn+UsykPmi58SoF5dm2m\n",
       "tZXuQOfWEWB2FfF4qLGmP4JjqhxRtM6SnbbPfNjvhJT3zckvEvNpJ3avn7Q5BjOPgr9aNs5Zs9BN\n",
       "80ApJY6+V+4g/4owMIYhyrmqmrQY8itVDSwtYbMZYgZVvVrQ3QBu7QZABA0W5LEGvEyLG0AJLJan\n",
       "TG26vKQo9GDhwJcKJ2zXt/WCFdNCqvpk44y5HkAvfhg8MXifbN5dKMR9u/yf6Nb0SMkrRft0YCZx\n",
       "r53+5GKS8xYUyJXqw3A7WqeYSrOys3Y+83qXlf/OrHfrCdaD7TPczSx4v84hxE2Emz4qy8BaG+cr\n",
       "nnMpOMxM+E6r2xUmwnD0skWemUDvyUrbWE7IkKd8InVD2J5g5GlJ3SXhZnHZvLs7HK8RuKF/n7mu\n",
       "gQUxTMibItWJX39jxvS7vugqZEpA9rQw9e0t26+ofG51b14QQpJpsnez+iIr31kS2STWN0SFVKkU\n",
       "ZAlCIEQeSO7Wo0AnTrnTUFT+j3hWoi409DXgkFwjbV3AiJAf8bfhZPIi2htUeLZhguv0By3B2aRp\n",
       "ebHp1pu/7/yMI3OkrvU8rOJLSwJqCJe4iXyTjbluEAjqN/8b8ovEmyz7wgNOhoJeTfhDmiQjzqN3\n",
       "aERvYKDgtkNe6XhyRiRrkVJ+6Av414ZEW3gdVv8nhMZjHQeOneSXvTvwjaopzsbnjm7NCQQXzV6o\n",
       "BJ+1kjBW9bwekCPecBPCcevJizPHul+2cbQzEyk2lnFlNwM9BaRFYaYaV5hbkahqqUvlUIerCM7Z\n",
       "wRIzpgF/QNuDAuhQ/dmpmrk3EGgGagF4P3dAUvzVmiXiVHGzIzj8ZgcMnkQ9ugPgDoTMqwz5wa9O\n",
       "nd+gQ0U8wpO/l8JC8iUn6qXpQdxB+VmmrzdAziJP9OnG5K+DB3DzSJ/CUSdokKEpCjz1Z9IHBANe\n",
       "WYwh2bVNhGcWE7B8Gj2TJu9K/TyLdt26rCamgxwGgNfYEaMU2K0A6+Pe5FdfWC4qFhrIfd8EU8SB\n",
       "chV3kY5tWyW/bVF5m206CCIsZsXXYpr0X36W6330HDKrOKsPlVR0DpJWVjUGJLFS5EgIEr5OwOgx\n",
       "7cLjAskJgQIaeAgvYyuagJ1SpT+m0FN0PYTupaPsGSnrs/e9jrBWPKvTIBPDOMU9oL/e1uGgmKab\n",
       "MiQs2c2M02t40sMYeKxfKCDU6xLDTP3xujRFCSACAPjP7vmPD8Az1Xpap509JPcangjTWVgMX/zP\n",
       "3cGGRJZhnasxzHLTZYE/vllyqH7ROBj+ENSBkPQp1D4w24JVhUAAQQNL0bqcQ7dqOtVx02hiedJd\n",
       "JOD7rFTszPnOomy/E+R3usD7LS6bAInakEnmNjWZVJW3KpZRBWYE35mfmpyNRONWoKE3V7XGye/2\n",
       "j5KAR9Jz3eugAGbBAAAG9EGaJGxBH/61KoAcdHSXxWIA253XoX7ONVw9ZsO52Xf54KuT1wDa9xhC\n",
       "YQIKGkvuAXFjNl0PcLyuVi1qp2NAcPdb1Z1iS5VhQvDKiHGc581nvKv3ri4mm9K4iUJrDUVGtNfD\n",
       "vrurv9WqPTmLCRN2GNemWIw9ye3dA4rowxSMJqt86I9xfjab2/kAdrlYXKRkBLQmfCvsdb8j9niH\n",
       "JoY1biTZs+hDKjkubOTPuGs+/Yi+qKWntSfmE5SA+TOdKZc7FbTkSY2cAtlus5qSvCsI4kwGxa1T\n",
       "9rlJmApc6Z9aBkuWPRGMU2ScDZYxsp7+CXHnYqM7cVQQhrMNdLkrXQ+AsAbC/QvjHaUg1JkHjdeh\n",
       "xvO1YZSLNjCRPCDG1FRCjBWu6ykiVH7BtuzYYq/WBKvB+//kU8Jpi2liIoKfdhDnyzjd+ECtF2n8\n",
       "/kDeBlJgPuXCUyzNjHP2Ig60A7wvuwtrEKNtgTEHcDrCDTsDpm3wkGPGNbfwrisRkfQYHr6yhVAf\n",
       "+l8lOo4xJ4D7qTZG83vlONrkRnWs0BDSE8koFp+3K+qnLFOa5hI2EvPWVPv4OlN9Aiut/JWy+PZI\n",
       "Kczk8cv5MYPvC0BurSOitBPSRWxWyved3zZeHsVBoDl/tm9fRnoe87gkzjkk8fCpbpDX8n/mpGlG\n",
       "tA/Qd7lh5mLiVC3+jTgVEI8tTnDKHqWcTdoLOrcmtjbN/yljZZ7PRpflVtYlj+/2gbsxLjSpkby3\n",
       "FFCip9QBfxfcNRdn7nLOZKmwEnzMf4Nrg5JAKn7hWKducXIKP7+VVRvyFBirzycxD6/Ss3B9XRsj\n",
       "H+Nf6e2Ib9tqmwgGiVMNj8lJDT56PGkF6A4/dtuwabZ5dA27gvoSbMdtwSsnj9us8zF9IbUp4QwJ\n",
       "IGALL/iakqZHC6HzRkylKFD+GLgjwHExVhyIllOACbrOPWa7mtLxg6P6uEKlbhG0n/7GyCbWrqmm\n",
       "EQD7Dxg+EXJ9i9Uq1L73Bhc4y3YDDA2MRLvO9U2aHqN4mTbcU1kIfvseNY5uNTwcPYs2dunq4frH\n",
       "PrGUnXFyzC3GqHKrLaV8oNeXb9gIiSue5/5lhVWBBIqv+l5DhHjHpg/gO6gTsEHJ8aHfdduYVRET\n",
       "sYu4ss8J/Shuw8Siuq4iyVYk9+q822FPDklTFfDc1WIwSKusnYJjisKZsn0bSZoFWiZuJgPcw+dw\n",
       "RjTLWuyKRfqm0aaU7S/E4ro8GKECywKRUdv6Dfeg8OOEALE/AiNbd3zNNJMj3spdnBVAh0NBUj+H\n",
       "f+rEpb/CEWE5o9VXLPKFBrNTHANP0Td7kkbyx+nxcTGCN4WE78MQj6TXT4K7RG3RvfBN/bx6lnYb\n",
       "ngBoJUcDk/US1vhUcDGs/LxKgE3RzcZ6koQj8UIuWbLG1Rcb2Mu+28dbu6cBlxTDIOC5CiwjNgc+\n",
       "VOGPK0KVacC6M70JRtiOn8bUYJ2DaiCbRhMuCdGnweeBZC4uoFToezCFI/7PoDILzGKWwF9VFph5\n",
       "DB08na470d1YCjMoCGoiqkr6InesLwch/dPlbP7J7jMO9yviPHEpyjGacIW9AJerrm7p4p3yfBVI\n",
       "vV0+Uo809aOWMaGYlDZpd9sGRyGjbaTBg1qWSTCIyZREg4yn2RxqfnfQl6yguyiZDqpx/pHf6Xis\n",
       "VUJqbQfjKYInR8wdEUGUqEb2Fxwg44Ywtx1WVqc5HvkrElWknhcW3seV5+GyWMHbSEpaPyyRQRFI\n",
       "TK8okBQfrvMHTE1BwBiYTkpu5VzaZZEN/s/FEp2xlvX2QSDJgzSUjJ1gnlvefSgAXfi9zkBoWW4r\n",
       "T4FCj5Z5SMD2AfEJhP31eOPuMl8QnnxPA8DkdEfhkrBzHCEMjbQ/LcR/Xfx5yuhPZdmV6Mw0BPoD\n",
       "lxzSII1hw1XbRUF+4yrsHs+oCYwHWR3B9yqr/KWS41eRE5vfuZFoEOJK2LpgzvoGncpas5QPAO+D\n",
       "fpzi4oaHHGnJzQU2BLGtn/fX6HLPWSlym5oMCjiS8YXIk2s3s78hO1+1RhkQUPg5gmej3kPwhrCm\n",
       "1PhLQmTV+zmsIT7Il4ZxaWQENYZve6mA8wVtnnT8YGeGxto42UfnbGy7lRnQkrvGlP3BaSCz1xd2\n",
       "+9+SN4MG2ZgkHAKnGgomwEn59DT4d7MpmPgTQ8B+SZ6GktfhPITkTSFP3RjW2EW/HZ1+z4DFu6zQ\n",
       "L8TlnXjOXFLWJ5xwzIP7wgIyN6TpkjKYYHkoFHI76tfMlHxhcRnKtq34u/gmhn+2PjaSoM5echlb\n",
       "7Qcj0ILG54LXo8T8bO7nUBC82J5xaP102Kog3O82jjV7H/YP2W9bSMmzijI5KzGl3MM6LkhfDWzl\n",
       "se48KP1vOTV/FT//BEY9ob3ArKjUDp5psCwdjMAAAAJ/QZ5CeId/ANmR4omc9dSi5OHr/mqlwAr4\n",
       "2GFqfvyhVrY/hadtVXqbYDO8yxx6+nRWUQqzes6cgpfVUtQOKp8AO6TC8Aa7sY3HxrD8RFJcNsNv\n",
       "wHE8GJanU+CctDr3UAVxl/pGNFvuAh8n5isb3RtEl9/Hx1ohx12DVkn9tkZLCVymp1ntzumSVmHE\n",
       "Y+s6RiME26QQdATk9PGeZ10BERX9SxVC/21FP1El2wPEpmLv5GqjDbmGIFTJB4RVmCjGcGZAwZ9i\n",
       "zGTNsbgs45josdj2uIPDkVLBKP5p7NueCMYCSxcAOY2ZyIKMEodoYv0MUQFRiPbiowrl+iReCGze\n",
       "DpFIPTzQ9KOtW9OjMEa5WYHApGw+7fAvmAeaPG/Mcp9tNstKWQ2D7VfEdIyrJEyTMlf2eeUk7gnR\n",
       "sNRHooYuBZ3HVHq3BkQNQm66qUHYPOorg/wa/eiLBofFUVomVCon5gf1yLcpySoZXqzghz+y4yJg\n",
       "Bux6Xl7TTZ+nR/YyCRfXHy3RrTz89PrkKdtINRSHHltx1VoskCN0O3Lh9D7rtE6IafAF0PHaqkn5\n",
       "90LP7fm9N9SG+fm+wVxd9R8z5jtfH+37/HBVhtp1LAvknTAVSqFq0UcpL+vALl87GRgsg1iSvWHL\n",
       "VKqK79sJ5RzKBia5oZXEVUeEVmoEwXoNUuZGoqu6d1zNgNNrYVFjAZhys1Z9OGuRT1Ol/wbTscEO\n",
       "KAk0Nn/vWpn6T3vwaFSKmVSGKrEbADRLIw2f5GyLqz2rXDWmVHpEOdZo8BTNgv6POnru+kAW4dPt\n",
       "ASGWAjHjFXWSwZGqxgdHZuoUcn8xaJX51lrO67z28+KEL4oS9BJOaaciUC0hAAABmQGeYXRDfwFG\n",
       "DM1QASmArxls+mtrQgBKTovMR4YFj+s5gGqjKFQOLSo6xm6A8/or3mXdyA9AC22aFndpmVPvK325\n",
       "TSYL9RlNVVrhAQGKXtSQEOHiVv7E9iVUvHLbs1MK+EBDO+QkxgTdK+QpsVij1ZO0qh7XIlVT4kiU\n",
       "9gNEqJSWPM7fRwngKwHOZ0RtIe7KH5YBUuH9wZVRPzLVhomaOIw1hbC6AiPvjOB2bdI0dSTn0Hip\n",
       "Lj3rodLsk8M68Ak8XZuBUJylSsQjl6NVtN3hgpuBIp0dGSVfvYUL58Cu4MVXU2Ga7Al89pbkBKIZ\n",
       "Gq6+WOGeWs/s8/7CKNOEwJ0hzL1C6IJFpVCpgKkH4I/rXOVDkoMShgbBcpUbYVUU0cNMjoVugh4F\n",
       "PqActtMHG/1qkm6mP517ES1GwmyTScrNnzrIfCqzjlN78Eq90bJtYVZfKazGMnH6NDWQ/JmOMCyq\n",
       "JsdYCtvFMWkB0lGZwQ6/vcLbYbG3GVN3xunhcgWb/h79DNtuT/XMBNQcrni259b+Sij2115cNKpw\n",
       "GTAAAAGVAZ5jakN/AUWI63UgMngzrBu4kxnVgChQAAl50W948VtT3KPdh4ebUuBHg/qmVAkwLz4d\n",
       "oNJ4CvYRNxrEO8rTZ/N2qZDKL+Ha0d4rEX2+GCqwRdE74lsj13XyTkmYcx/a4xht92X+Phg/VIwZ\n",
       "nY5UgYMUjAo5t3JO6GJE/fiNbAGKC8PJwMAK9VDj0ljlOk+VT7jYVbpW+Da1Gjm6au9d1OmKgIvG\n",
       "KPzIzrgd0S+7bj9e6J2UJBeVk3C686LJRTGfRrEnRkQLHCYSJsxya0oxzMPNE5txcJbtFi4C52oX\n",
       "jFLpVgPtwR58OEpovigEBHyFRXkHJFMMIMRhMBaJWoepf54yK1ypJz3Kbu8G7wFuuNnd1J058YlE\n",
       "wq5pZEZpBsOp1KmBkLiTuIe+QO83d8LRN56KvQwn17YV70e57d6TX0hBgAkJs+Si5g1Mw9WwXj8m\n",
       "s3sVMk+trehKGGMphZuzo5aetyZhhiim73/lbOh/4etiQziobhblDsDVrjIQsVtq1WjS/rANWZr/\n",
       "kn8+fUHHVABt5gv5AAAHH0GaaEmoQWiZTAgj//61KoAcuZznigCGzeXt9oLl5aARP4cIrdmzzGEN\n",
       "/hV3uxpXOX/cf4PY+yB7oO0l9F2ezGvghkPAVqwLMhbCM6Q21PR5wyu4k+9VIDP+FPczG+g9lfcE\n",
       "3UJoidHgJpbTxoCInldgH4l5YaMZZh8xmuml/kLL1YomB6JpWl7sYoyM86a4Pp0+LaB6Ce5WceKT\n",
       "lmwxUUKYWpf1POFBab8Z5LeQRpcauSzbRyIDIx6j0APXEBfCrgGKdcaUyWb0uRFu1tDMDgFRU2pE\n",
       "GS8+2POE02Oma2QmHXy6LlAOeebUaIIzXt+u3pN8lTzm6sN94IUaF8Kyc7GC71EHc8ycUcSR5RG8\n",
       "BWwlHAFex/0fbxy9S8mNGwb7Nk6p1xP13es45FXKQnzRMTXU+HgHbMybqQGx9F7nTj1nsC8kIYrJ\n",
       "3xtDK5HqFifrmdbOh6p6WUybC4n8YIqaqBlWysgGUeQKiO1wy4kV4hnELxTo3w3n/NBgCgJyieD2\n",
       "YxEd4CaM1ndktSbXM/k5l476HobW8rhGmPkxAMBS42hQGufWxS7T4daBEY5W9Cbg44ixUkvsYwVR\n",
       "lQ4rsKTCJAIpikW+zYi/zf6sslQd9Aeh3ALgFKr+T19m44G55w7SqnWBtVJo2zaY0ZTBWbIQmIei\n",
       "VA0oZzURb+xb/rSnhySbSQokLX/CR4xef21bz/+zfXoCk7qEFnov0y2kK3271j1rbhgtB2z5Qevl\n",
       "UBorDU8LN9O/L9iB5NqWXOJc0F2ZNyLZ4BTlNI/bgDHSkCtv20vsvZxNJUDoQYtzcMnXTKinfS5G\n",
       "w4cvdse72s+ndP99D0zg0d7gC4U42GVnumIIsCgEVMhcNh/zm12RZNwPpJE2KSaQmmpKcCaerV33\n",
       "LUm1MylzCwgle7qEnIVkFkPlELue3WdUg3oLERiYNyjhIoNSGDsRdh7emHllAiGTjknhXljF+Sj8\n",
       "KnpcNX22gyaxmmgdjcjT64FsrxW0aEQAiIRblrJJZCtdb3vknBjJStp0tKxc0yCNNuY++N0hsxQb\n",
       "vj0VfoqiOtcxhZrIqLRaJNOtPhWqlShRUO3WGOiFqE4vP/O015wBd7cLNl0+xzf+LjCt64kjGcCW\n",
       "z32/Ki7nxgGpTyR55/VqJLrlrwuDplcHJTKkrDuNAAVSqIuE87YTzgXG+cE8hM62rbtMuFkvjqHr\n",
       "Xhj3UNV+fFzA8FxoJPbhfAX30JCjeL4RKpVhZCs8glKPvZP7fVwhC3BlOiHimZNEBGeGSvW/ZtMm\n",
       "bMIihqVkonT4LgzqBs8//zNIsgQo9eRijtESqhGqXu2laOY6zwH05YCQmq3DpAFz30M/fPyg89vy\n",
       "cRblIAlETj1eyUKCNJYpa85eMH+mlxu7VkjAOmKKKqteB+silM7dVpT18E6xI//TRZr0i+wkwtAL\n",
       "UYA4h3mMgpJYKRBlseXP5I5ScZWjpWC1+8OZiRV61geix+QZn7Rd0CV6n05jmLY7gj+3gJ/qseaD\n",
       "NAt6hAs5XemO7NjA4I945mOQvGKhcJnxCVnr12BXSQ8YJuM4A4ca7orMk9i29rB+mVB1DWFql0cF\n",
       "LQCnQm0IacOPgb6AA2pYjJChvAcqtDP7ju8g5qQMLEpNu7y9DLmWG+988Agv5/LZxeOeUi+8fEti\n",
       "FSdhjz9o96IknV8BldXkw9vg27W9EYS8DddG1+6emZaMcRVFAk9hFSHgTDDmxg7q9nCvx5keySTe\n",
       "IHQCdSjR9Gm4Dgtc/JnnqszfIVICWHes01VEHkvK+XB8+weN2kKWUj/e6mTDpy6Ujghl6yZeVo17\n",
       "YIWxPHsLh+FM2tuXz1yly9OkLPR9+jMpIa2oDhYsDQbZ6d4cTICQl9pUdCIPfkJY9BJ/7jxAEZAf\n",
       "Y1E58UAG9rOs+u+gE5qKIrbsjgCGqhM9MI8B9Jupt+nM2QlhJOvWv0nf1/9PUQkAf+wP6C3V5WR7\n",
       "zx95NxagrKLII/XiIHpJAEHdtx5Zg6nTE1GjFt2D/PEfIwG82dokfq4LOjFucSAWEe+Fwv3lHPVl\n",
       "OHRH2+HeiK+aztbxU2k9X5rhWfqaiiUqrPeWiSQkF+2aiLfc48YFwi0sORA322t0vv+OHlRZPbOS\n",
       "L/3PvK5F8hlfEH6/w86qqak6u0x2xt0L3fsGAdXZABMZY/OunI04A4yQUGG/OO9D8k47i8VFBg2i\n",
       "8bxuM2wBxgD+39iOzxuEpBnLHVsJYWaMVw/gKCeLc1PJbn6psQnzxmI1b8zEWj0cEAaw9C5VKc4T\n",
       "yw6xmAdQSEKFF5eHUzybgDVwtqBl84Zx33jvYuTaDJfWaCrGBD038qudb0vOzt7nQHWc6zXD9fur\n",
       "1p5LmVauZanGoG6uMydgkc2nfQKoZc3CJ1ftRMq/2qmH3wCF3QIphyG9xkpTAw6mLm2CaKEEyqgb\n",
       "mnvLBFhlzL8eWbSFqu8pAAACX0GehkURLDv/ANmQ1U4b8zmxeXJRBfgABOKy31Cxf5jAPAoCLomJ\n",
       "aTG3lQlqlkSYjjDzpUMIiImBE/wCrAkp2mqg6Mvxg+8FZ5KqqqaEneDsYevEeXcoq7Cdm1KaQ/mC\n",
       "QMLsTUiVJ2S/SOLmkKq2sMMk1UppAPNvsEnDY6VrM0QI4fR7+sJz0c3ulMfwZlLHnnEgsmDWhaVL\n",
       "pHvGUb7HQJ6PM4hW2HQqw7DuPVfeV0L4eSPmbN4C439CF3ZqD7UEgmR4fo0wWIz7eF5KAqLVmnX5\n",
       "6CJecFkBF+yVBATptCnB6mc3k9f/y9D+/dad0BqHWOY2FKF1Iz6d8l6bKuUHqQdvPhuDhrePsEgS\n",
       "cWjVg16VgEsKm1Bk/Q5CcdywFjm23gQjNteEaRAvS5Qc0HG4wtVawbwiq4lPkG6q2elSPDVEHjY1\n",
       "zpNIuDcShxNx+mqi24dVtlyPMLAe0RH+/cl/tKV7WPXKK2I5cHhToN12P27F9r9JiowBVju+3Qcp\n",
       "dMiCoSOP7+35XbJqSZORLct0QbKR4sAqPLlG0TIhAyTwOroIzDzzlfujT94GZIrN2pQGu9hYoIdK\n",
       "Xe+TWD5AfLYkbPpBuOUHhXfSqsoiPLvrlv31VKkw2FYQiELQQJzqFsawEUBaWBLbhUS6foqM+eyc\n",
       "HULppd031pszsHaAnGGQT1Eq/f6ix0/IS3I5a4s7h/f/4D6eYWiwZ22ISTmdJWGDECOFQv54Q+bL\n",
       "PhCbajrQnbBabgN1JRz+mvjtaNSomPGdaj9vAf4EXrBHr9XWKP4K7Jy9hqcdn/Zqk8JQLKaEVUEA\n",
       "AAH3AZ6ldEN/ASGxUXEpfCb3fmOWHdFxUvhWNaTACYXvHWvzIpcxAMhGdS9VfqYygKeyLO1ryBiw\n",
       "zfhP61G3ZqaW8s2GGfTS3DV1f2b4DwnNpE155ah3WtYdOaIkK2+LLIAT16YpCYgasAv7XjwWSvOy\n",
       "0ReFudl2XNjGNTU8Sz9RNbKVC2G6mOZUELM6EcjqO49uzkilHWKXRESLif5V9S946tii+Cs1Nx69\n",
       "3jHycvHzbZZqYljjN04mNU0oW6xgW27eJdWRuhdf3AWBaGK+VDgGG2oLfXE/48Lww20Yih5DHG7+\n",
       "RDl886as/w7+AZRCUYWRr4LA/tMQWLPVFnL4h8nA57tLZncAhrfq0bpJCm/0fVeGMW3tXUWHG0Yw\n",
       "JAOX4ZGC+M52j00jyomXW1rMAZ+6uNazHpH8nbTyaJgF4zbFm+vgYA9hi89/pZCKcRlUSluhqRrY\n",
       "U9YManXftDgLCubpWlgUzcjw6hIApI+6Ngkp23RqZ4pRmt+4QgyZUmK9j1beAuG1qh3z4l/Bv9Eu\n",
       "gHO71SB0kHygeXLadkTgdKOOM0oJ/ad+r5um8r7S4qz3Gimz/MwTnA/GEEqWaYF3wtDPD1X8s+58\n",
       "/iiwvBmmP9uc87v1bYsW14ST1ztt7pqEnUdHh6Xr2s6IVVwI6xMWUo1jZxaQHx0JB7kAAAGvAZ6n\n",
       "akN/AS8fzS6gZBiU6gA+tegKBVnEHDGRONZGXvvQ9rbAwDRRBDwmn97MLH4vgv4LXqf2ksz60XiN\n",
       "uQelSReY9/FdWgguapTaYpRtRrQ2zmIcgQWxZvucbxzcspq5VqL1Kx/ok7OTPwQ138Fl/fnZ9OF8\n",
       "snQP7BhyUTaK3kkr/NWrJWv2oZWrW5jEenFP9bykaNNmLjDrdrdRXSKqJveCj1a75BzlLxHOsEAf\n",
       "trdKQmMEyb0tD47rjXjMn2W3JdzkIz+CA9AB9r8yPsUIt3iA1NdHl6ixluD6cKBzrgbHK5I5rLvm\n",
       "CKlF1NaRR8mSA7yn6Pv6ZLqdspccrz78WoCdUSZgP4iy877qVKKkLAJzhGn4y6sDgor1GYdvQq59\n",
       "HwmXQqDY+Wgez/IGK+gfMxItywBknZAA/xrb4JyQzZJYjiB4du4oZbfS1r4SQUj0xV7SKxerroyA\n",
       "jrztd7mk7KsS81lLs2V0g7XjHQhx8p/XBlAeU8FgMpKsf/mI2m3NCwWPs5MPJsWwIbWzyU/VXUPe\n",
       "VsfqDmlLoIW34cCJTsV0TcDnhKl8ufjHCRDY24AAAAagQZqsSahBbJlMCCP//rUqgOPoMYhVceyp\n",
       "9T0GADfXZADTXSrPwCQR8vE/TbnUGFZBWYGClvpf9uImE63Xuop9yzwVNWTxCK3zPP42TfA9DN2Q\n",
       "dk8dbfm3M+rKdtpuhtDpJv5q3hx8HAREuWZHGHQGoXhTAWZ/mvSpYdy6+Ydx94JQ1bdMKYYp1Hmz\n",
       "B3wv36A+5fYfdZ2BKhvgs02nBKQYObWx/sP2gr2HlfNvOOMrrEJ+Uo/MvZeOXkuv6iUa559ZVol+\n",
       "ojTCAGQgk0eZC9YiDjPHQFe23m8wbT6Z+tqmNuV7f9dB2PegFP9nJU14KPzaX5s9fAaB7RciwlOr\n",
       "FzsljzXbbRLeRYQFkNo5/qG623pSR9W/Ic+56X1JYFvYZcoTPleSd5TpxqOpEYBXAxWW4HK+U45n\n",
       "wF++ELxJsjhDj+jvf0e+37GeDBJ6lGA5LGLxGG2o2EmU8gl1GVNag52t92ljiiX+QAQhuYX28+xE\n",
       "/OYIjSMbYmiG+AaeReobBMBPJ8HntZhK3OUg/jwnOjZQuSti4VywTRh4Ri2snkGV6gQ8CwvxHnWV\n",
       "P0zT9Hx+YW8QpxAYNQcvF3RXFq/uB7EoTUz/EWmR3ZcFrngeEhMoMVcsJxjN164hVsw2CxMy9nyi\n",
       "IOGh17e8Fs0SL6dmEl1ay4gObLNSiIK/F5y8on2Id2pKP3OwEcBibbMAdlxOzcywaIrNhcxzRr0Q\n",
       "k0aTWPHe3tp4Lf/GZu6ev+1ujgiTtXNEGx7JtxnKS2mR+d7YfgK4FOpIosHkfGKKFPHKa53XG9PZ\n",
       "51lnjdNyiPpCN2/YXJUwj64h8mZtFdi3bPv3fvQwKmAV/3Gx8sFxIABUcrteHz8IVCPGLjHce/09\n",
       "TbsgNMDChYw9y1Om5FK8tFozG0CfybxbQBAk5AarmwBRX1Mi5NdipEIPaWRf1qYUmkG0L3gDwnyq\n",
       "ZVoymlRSOMKIEpp11W3p7KPc33/nr6nSSQ0M4MK/6C3yS6MOln8Pnum8nuNjdQzoVgh/g42rhoxY\n",
       "oF47OSFiYh6k+nOtj4TgDfPEdROyzNobB09WLbD7YahCMLjZBLOGtL64vmBBpvh4whw8QXaFh07p\n",
       "QRoVbaXBqxx8gW+m3kITCCYhrC2hCCUX6vqEiqhAhzHKKHjjopx3o/4aXqdaoUF6Qi8xn3PxCyJH\n",
       "K0IW1Q7DKm2JZV5shObst4yodgF95LTWpDbsZVPg3v/UQo+SbQLdSoofg2DSpw40tf6dXXRKPoMA\n",
       "uyyV3bvw4J7rC6Ab5cz+Z60lOzzTBjeNx0+YZU95Cc/xE99x/ZB2LzzZRP3BxSTeLrBX9J2z3XuG\n",
       "tvwZCTelgXFXhn7IOXsfIg5YdChLKyiYWY7Qi1kmsztplK2IQEx9BFaeNvsceGOBhszdvE8fbyZj\n",
       "L8DZSt7LtBoeP/g7Zq1I2vsoZueDMw4JwNwubCgHVrNkf4N98O9uDNnpoEzbyW4bGTQvXWrRAFvk\n",
       "AETE0li3tkm30pOcWNsVDnCTa9pS7sjh/XlEQC11hrftzcM5QhsNxp4M5yOYSVeeLkby9ePbaFKw\n",
       "J/W71H0M3XHJGDQbR5eN0OsE46D34KqM2Su+wC03T+q5xnA8TPjGS5CKlAXPo89TAqjq3KC84/fR\n",
       "oOR0OBwKgZ9NtBQwtgir73k5Pd3iU8Ijlrwl2k6sOKH9U2GBlqQ4M9JDqZYTuWhyHgbd57EtcEXv\n",
       "gNuXfd5qLporBWtuBYbsdIwEgD9rd650M0a3I5wbBAiw1/lpV/dYyEWQZr7AOWpoHWrp91y9VMnl\n",
       "D0JkMEyaEHqA/hpQvSs/3cUSLb009UzEUK0BeUDFtGyFDn/BTfu3M7cle9M147bY/p8r3YQRm9+p\n",
       "cY6HRhlDln2YHPfiuMgmrTEpjvpEyj/VP32GWP8ypEBcB8XMQE+LiMEJPIbx2hZgBwG4bZS7OrjS\n",
       "vBsbDTBn6dTSsvGGUZkiD4JxCM21kiG+SRdCeZEtChGVrtgB53MEJymMHojyCPNDnsWbAuZoLiRK\n",
       "qnrdkamj65jVAIyLQrxGhg//Pv/LMhCYnYlmeUR0gGzdmoXZr4d1nOd9wqM/N7Hb2m3rLHFZfIOn\n",
       "YVMcUKolmySJOh4q4/8DD0WGUfqETLHPSs6bKWsl2+OJ3Jl9r8NI7OBdm81lJiOjsltExaZOSddR\n",
       "bAIN7Fs/5OUICzl/9opMen4ATPFV4A51nUkNhlGSTPVG90AEhGAi+WQJWigBox3QRRxyHbhxAPLJ\n",
       "mXtw+egMKFCQXBsr4A8msRdfWAAAAc1BnspFFSw7/wDZY8vpScQtIEQWx7QACX41jxIHAhRQpDfI\n",
       "Zj6awQV7EPclUWQPnY/nvDZb7V4JZWhYdRhbIT5aaJtVI9wtEtj1bEwZa5OYly9dsjIMQLWy4Rst\n",
       "AJdfR3uUPs4jb+pcNn7INvL3D6rKu2q+ekeEgxmiNPqibh3JXbivzlAhAHbH7i0YFgEDej7aSy5Q\n",
       "bSEcVvr+lKlyR7/4/wW9TDYFgdE/dz7JFc8BeUhr0LscPppFBvtnVuS43UvfnXSh4Y0KNE9n0zp7\n",
       "kJM5OvFLB3ygmzE9VnzfLtStE75I7kAbcqsBvB5TtsMHGSWdxnHNm3fGq+B92tPPFMPCXISCHoMX\n",
       "QofzR9iHWvRiRx5OGt4SQqmgrcuQO+NojrvIohpOS17Oud6Mm9FdEmLaJeAtfSqmY6+vokv6RPcp\n",
       "D25ALYhqeGymu1RLnTUmkqSyz6oHCqiVH0GmGOTEsbZWRbL+FFlnyBvqoJswPIr5yFcl5sbFglb+\n",
       "SsH6OHn8JAay+HNLS6Y3W3fk1VydPBGVH0s0AfGGFMlJg5JkttAw8dLvb9x0vkKos1XDrQnaENFY\n",
       "RDXSUMhRl/P9zA5A6Aot5cEBj+g0k71htdIe8QAAAZ0Bnul0Q38BNTzksBxjL7WmgA95XhJYGUWY\n",
       "kIAYwQkG/I0hriw2WdMm8alrCX4zO3hZFhxnL8jCwHa2eLVV0+5YibhqMGfa7CdFMqFOapM707cX\n",
       "IwCrFaTUFDIxdBYFL4NwDGwvzZEWRoOSYYfEcnZdwjst7OqIceQk6C8poRN8obiclaSvTqdYvro8\n",
       "Ipep4eFCUd0tcEw0/sV807NePTWWsSqCru2KCRq9tDM0B94Wm4aORDF7JM9uYDIXBsDxdFxGyJnz\n",
       "kZ679U85/BscAfu0DoNfLRwzmnrR0Hw+vkV7OBUsSpfIWTfKJ6yikaCvVbEa1xweW0rxpYOy2A+5\n",
       "M6z2TWwqACq42FHGBGWfcv/DyIW5spapQFe4gd9fB+tDFgBZoZw2hWe4Ip/8yh7+1I0RjO0wyxUA\n",
       "XrPSWGyXWDp10MjB5SyKcKIm3lP1m3TioxSfEki2h4Kgi3fxzsaJtTOodWpV6Y8h1NgII5LfvKpn\n",
       "ngwOyDe9T+kwzmBEL5Fk6/JHMbKF63Xbr8e7QwUFsGFPNaPH78pAGkMQ8uULaAAAAV0BnutqQ38B\n",
       "NTQ4wHGMvtaaADz10K1pgw0m/3XX2BlaAgUHDYG4N/ZZ5QJOktFMC7ICVlJx8gSBgB4OskgXewRK\n",
       "8PFQ3eklIcIo9b3syjlHSoqcEaUWJf8pr0cdHIrWH8MUO4TxIn59m9H1UP96hbxLETVxjfP3oQvj\n",
       "KoYfz0fbgts8dLHk+/FJcQVAzXIEhBhfKZKQq1ZS2+JNqZRVzIYXm8VtPpxuihPbbwoSjhvPSqUk\n",
       "x9rhrFYRtGjHPkiBfwdQlThY5yqdiDqWILygdxvYCwX+uYNfY5OBbcI6x1RKnwGJt5FlG3ZATSDi\n",
       "2Z9fzMGYmiiS8A84Y0apIIzTh3tpguVdtqONHplMiE8x6XqiGZ/zHpnh4Yj65aALQTfiO7axxwmg\n",
       "/YjnkG882fk41SpxWpIDmOi8Ibvi0TM7PMP+DL3UC3sYBWvSd5fWGCsuYRnoS/oKXeb4/XzJZyQw\n",
       "AAAFSUGa70uoQhBbIfA1AUEDUBOAIIf//qpVAVLXDBAu1UUAVO3FAFYXs3hQpTquXNBWfeixRsVO\n",
       "Q+Lm0w+3crML2nNrer88oPHi650PM+fa74FjJzD+GDg7J8dXmRmi1L4Vj/DvFBJl7eCWQaZQdy8a\n",
       "PcPQ87BurXo6uCwXzrCdzjK0zMabLyO2zUgHbEzEipGz/LhmS9OrRDb9LpNVOxBUtIFTOSYPBAjL\n",
       "J4y1dyp5hfI+0rgyznePZuSRJZF5Ea2PZC+WLjv/FaXMgkgRyDuAj1DZ1tH6OF/D2wRUcVSnSq8Z\n",
       "l63P1AkvX2RY22i85LD/+ujj/+whqJRwAIJaZRZQ3s2456hIALx3WDIPByfRQ5N2ttj5+juz1SMw\n",
       "lTeysYQSLQkHktaSKoh5yjhpahNRPgj+qc+QvWBqpgAMI8tX8TWWh8LUR+ga+/knMJZUDNDZd7ao\n",
       "u5MIChcTDK7NQZ+A4c9MVZdCVCZMS5fT6KrFQqB+QnFvQxImqQVePhMA1IcRFws3WotuyePhfYf4\n",
       "0EeevyoaSOw5bxOnAeHD17yj5y9QBXnCDtQtmh6ScqEQdSpoDlFJoTMZPuX6YyJ9J/BrqNr+d7En\n",
       "mHX5D6+jJFWJYp3guWS/YDxNZcKPjfHM8aT8zDu+Xh6VsmYW5pJkAbjfb8NszTcOC3P+vwHxQK9G\n",
       "0zObroeWx2CVdxOw98eY5NPEHYIUhQMCbjxAIs7AZP5nh4SpSugeWwdoaVvQv/IlwK5so01WIAgq\n",
       "rT1qVYSYhotL/OHQhDH9ilSU626MyYRCAAJ2BQQGPwWnr5HM2e/iO5/3nf3FOtYeSJbAIh1fWzes\n",
       "GeON9DHscTgXdx8DXEGpblvt/OrNDdqqhhw6TjlhXB6yhswNAPCIBm74fUEZNv5EksfjS7PRecK+\n",
       "3YAkk+wCWg4oAA4WMTPLXSjyTsgT/Ma69aSNkhiMG1YgjQ3Xgf6sSD5SumySlyWtdGEsurCYG+fi\n",
       "WAVGXgREEA3AgtFGHTnW+EJkmT6ucHBu2VAJ2JdWPAqAyNW67V5e5YS2IoMey1JA9gLuUjY+YLPS\n",
       "Oo3Ox3gYbY0Pas9M7zhCVh8rZMp/dUwQ86Tss6Vk9GJUXwp2cDQzf3BRoeQWuWnzyEY5/RzMqRUI\n",
       "pkK5KHPQ2OVThA5+rtw0kcA6f1lGtMGD15d8C5aWa1TpOwWgJrvdBc9iABxNFszOcfFuHIBQIwGB\n",
       "8oVXRnUrQgPCXzlK25k2x5J8OooeGbUQsLQCyMRWIkRjhzwZiEBY/8gxAjFvaQUl2vJAbfNoFsXJ\n",
       "KMeoFXPRn6cKZtatxrhmUzd99Rw9pOHVUqUGLP+gBrMZq9pz/bLewiC4Ygv6vJOjFYiPERK4NZB7\n",
       "0uOzKsvr/U746mb9SM8sYaHbAVFNmQMtp6LTUSdmedi0AdLTnK5UiiGUQlNYi5TNRu760nQbKQ7U\n",
       "6lNY7/hdt9KzdLt3buooaanOs3laLMt5bmrmqLrjhoDQ+cqFqcIcxFCEGmfdze9cMqqhNHrWdv0I\n",
       "VPc/F/BjY7ovBmQksNpu9Sq8GJOfLjWVT4QBR/7NE1voeI80oArxjQ5Of1sU35uEtdKPyJJ4uNJl\n",
       "F5/5x7u+WXZ7+EsWeTRe+WXkAjIh41wafsBW1HLBSc8aJlXz4VgYxN0Yc2wemk/R3QwOyWUWf0Pi\n",
       "f7vUl63lldvovuJXZ1T1wlQA0YDqYXqSL5MxR1MXPaPKjlbKSnL516zy+kraf5zT+DR0gHP+FUOc\n",
       "OH0v5U/4O4ApT47A9CHc0zVbIu6j30W0U13h+w6TmqC1KEHAj0tfjUblHUuAqQAAAbdBnw1FFSw3\n",
       "/wFXJ6zUUGa1+GYzPXCkVwG/AAGv/SxDD6zue+WVmMzoqXiWhjSzHGz7QlwAsqX8N+H+39NSKIjl\n",
       "hEwdNh1rvs9p/ZNAWrIo+d7Fub/4GTeOIDoiIGv6mPurXVWoYkZns+5GEp0tZAl7us4FMN28R2RA\n",
       "JGJgmN0Z2XW/d2g3OLXt2exE7J0wl9x++hVqqu1K69LK3IhtA5Vgdt+cdFfYXIpFfJo6cckY0wZN\n",
       "NfzYsDfd3y9c5bn2yoAzmY8/sG+MxgsU/kDs6JVzY2REwcExQTvP6iDhQfBIcCyNL70rdGC0wgoA\n",
       "Wq16JId2rZR3FVXRpUDIom2TFtkj+JSG4JmENGGvEVvvBCFNr0q1Wfm7fm+Yb7rrfKjaxRi1lqLm\n",
       "VTzJ4SZi//i1vOGGtsr7wS4XYiswNSPd4xcW3nRmI3AnuX/7z4vqeCEB7f3Xpxwzci6YeZ0KFIT7\n",
       "T7tCjqbUoV9QPH01x/HF9JSfc1Df9K8y7IJVtTjkbpCo2COKGz8YYXD0SEc+yjeIcuUKtY1NAQEg\n",
       "SCvBunzdpD1htFwWDV7ZffE7ULjNPg4A4gcD8zT4eUZlAAAB6wGfLmpDfwE1ljxe6i8lhJPB9i3+\n",
       "RZlxoAPcmkAaYfOOfBQ+2QyKGIzd95wwqHa6hTKl3KlOsbQFB/70dWOYmuemPFS9GjBNSzKRUyml\n",
       "aoWP7nr3IUsk7QOMl54QUPdbZPkiLH57lg7XLnv3OFZoTZpZfQQGcRn8lhpu52egxgn1j3u5jmCW\n",
       "nm2VtD0xKtljhmfDfnOzuvHv9dYD+KorC8+kWphXL7U0BYmX+/CH83wqo7PJj4poaOlNt+poVPMJ\n",
       "2Te03WbBvf7xp7/lZA1VLkMXBw00Ju5vTM6JlqxoaifxbYHnzjF7NqnO4kg6a1n938LeZ4724DJe\n",
       "/z+LXyqtxGLxMJiVXjABwjHAj6mS0xwsRp1UEuArqu7zm0KrIc3biS2/B3eOvgv17VF4finifj22\n",
       "bDKzv2RPtPLKSdJmdDbFezXWQC7c3gjTetvnVJXnMYnYXEqn30zGTrmjrA+5+dFotbBJjTly4OZ0\n",
       "c0AiuBfHjdKA52GdBRwrUMC9caJ9pue5GcKJPqznU0z1kj0UWhzyb/LrUXdSGSqCEb02Sb1+mvAK\n",
       "BWYqVSMJ2LQS2WHvh++r/Ky7XMufAr4AaA1T211N1BSkV6bkCQpBlCBQiOiffaDfHLdknpedzjLe\n",
       "YRUpZ7Iun64BSX3DVQuJAAAHl0GbM0moQWyZTAgh//6qVQHHxevVdjoL6X+f8SRf6gCDczmU0sg8\n",
       "07vpVuMmhzN7i4JtcMo+JMZajEkw+T7/gS02a1efw+m/DZx1GLSiOKWrWg7h7012mS8qbFUdBYUe\n",
       "6h+dYaNkfvx3qYrg1vrUG89WbE0sR9O+9CeV5ra4oujhxFt9TMa3wYR/VQ+Ick2w8OUwzxjQx2J7\n",
       "6/9soI5oDPvrtMP7JaH4a8i2ALOfxRgh9JThTaYko/HDr+MDsbQHVvG+gJ8+bk38FSx9QdeO3w2p\n",
       "NEg2XL4HQN94NUNrzzE9Cg01b/ysDOt+lPNbpYBBRLoXvQRHfCt8sOe/jZZz+fWV2celVlWNOB4x\n",
       "4dhQOuLKXSZ6vh3W3/xrofjeKlAO0SNRglOS/JEo0SWO9WFcCFRhzYgBvZCkUbfGoEMkph24oR/e\n",
       "5hUDe/MFdaNtO1PPeqGcJe+ek25zWqslV+8h54K8SV9xPe3qxF+OgbLRqIAJyoxVxB4GNw7oQWk5\n",
       "9WnxwQWAXGXKFQDtMYcUq8gSDaLbtzA+Lzqax1IKs0epdgIQmmn2Pb3C06SqNSXxF8QHdenlNUBE\n",
       "7zONgLo3hPwV5MMGsnQ0+rDs+iMVYsbfjoHLcE98lftlyMusIGMfzX6BeOrLUoo+KQRs7d9NGHhF\n",
       "ZL6bJYVR24p04KgixGJ7CFY8aYzZCvaw23n63UjBBVJZOVoMW+t6jSSGt6+yYD1kI59ttik9qQGB\n",
       "gRch4S6XDPaGNKCzZHJef2dO2ePkHJNjVQErohoulJZG+WrxValM081tsZsIFa45pNMjLqzZCiW3\n",
       "lNc9EQ232EBPhm2ofQmp67hqR9wy+lRLRFJd3raNcYqVCon/yr8f8b+KClAn4dszL0IkHQXjQ3rZ\n",
       "v3omSt5u4MldQ9Dh4Y32oSO4SJO5+4VBc+5Ujd+XYC0Dj23WMNEQQUijlXxseSzD3xw1l5dpWAyy\n",
       "VOAR1R9TL9kqipXvNVYJ6cjwSLsoU1ckBLuj2uIvNXhuHJi/8fLbRMnAr4FXnL+xK1KDSlteDK2Y\n",
       "IbNy4IK3NXPbcfMo7ULlUDwMLMkNNjtd8FfTvgGNBBYbitfSbrsbt63y6hZBrOLgUqdSImaSWbIK\n",
       "3j5cKyEgf0czIkX5HcjexrlncVsdUvIHibtynxJ8cNyZ5s2NyFZoidh5aIIVZXchkTUzqYy+112w\n",
       "RzAqn9vziNWFZbnytG/dKJM/4+x9Pib4JbWfYefV59CvSWUjxG+wF+tIEtjikEIDFKw4VmXVtoZd\n",
       "rJ6ycy5c5ZCX9C7NSDk8GY1GAK/A56k4WLxwQdDdm2BayM8cWMtiNq2KJWOxkEcFEfxtJeKunuRY\n",
       "kJgkr5HJYIjTVrV0Nzp9iZOB1lM2XtSq69MKcAjImS7R0FPAxJWkCIpV4AbPujg4ycWV3rAPfpyC\n",
       "zkq+TwiTUg3RvDGXyy6Bdk9SoMrJayKwKKRwpsbvrJG0G/vNiXFhBMtFTsg6nmVp/QqRJL4R485Q\n",
       "0nFxeOGdJMlTOk2blGIoqtzZzHQq059aRqXZkB5UeSjde/YYYh6YRW3618HCLO6wRcq+IHJOIiAQ\n",
       "F0Nsm22ENdmcbX0lhuAdFu6XU+ieSUNhz/frAWb9UztHRh7JB5uzNZzw3aRbLyJHnCpL80uUmnwR\n",
       "IDsdO5lvvwogJUwuBrarV4Wmc0TDGRsMyAAvcAeGJeUtFbV8JzBQd6RDNO9D2JScrFyjA3z4oBDm\n",
       "ujDAfiQXz49/3pfwVvX6iFlMqdUa6JCDFdo5LuS3LPLhF7DKk7LFjnq85BAK2lhmguiL/JKv3l1I\n",
       "QcjCIHjUfR38jhSc7Dh99H/Yq02vgXQXFDBp0oXEHpwTQ9fq9bEX9I3whfMocuiOW/9bhYOJ1YHS\n",
       "td1PRwOHv/z+3QXZaH1JxE9ppVqsv53qH4znCg0moP5LC/YS3NLdk4wZ2i5qEfbXf9xhPCwZwgmE\n",
       "M9pWutuk+p4Ee/jH901X+NMncE+ozREDNxdhjSBKiJI6AjDUjjDgrw0JinTU4bpkdMiBqg4WltP1\n",
       "iLMZbqI1fb7yoYkrCVA/nDqlhR1kOCqBEc7b/4ULuMCz/9RJRrLiP8T9Z5D3yfKER6S3Xcl8ZVGl\n",
       "WkeIf3VxZw0pEMAWa9tGekVVDCBARwUzeZC0ADEJupOykLunoJ2dI8dd8uTsa57qZGxP9CGGQ+5F\n",
       "qqwbrHVJVPgGddX2ZO7gN9LHp0FHT0dVmBzuon/v578uT/86jVeu+ZVdHRFTlIhNlOuPn2eUXF3d\n",
       "Mj0Q43f0MKakiUPxsRRSJKOxFCQE27bS9qQU43YYaneTqa9vti0phneqkqfPDyzqe6UCZvvLDhWo\n",
       "2aU5QHKvQOgKBh08Ygo/XSmM8fS4FVZ/2gsDIXT4EtB0RAU0QiiXRf0mEwqi7WGE1GLMGxLFEh2r\n",
       "FyDk/5tcj7B3jid3/c/3OWTDl2RRTmLWdj+z127tm/2PFaZBxQ0viiO2hfWD0eEsEbK3Fjd5iQc0\n",
       "wMMJlL/Dr0AgXemFGhrlzbXvrS6ed2tkryaWxZV9od6ZZx/Pb1wwR5gZcCbvebTG8ajTt+eZQDl9\n",
       "ZOc8gEIMl6VUaUisCP9L9l4BkHexrok9AAACO0GfUUUVLDv/APG6mrd4mdnVAb8cAAts8aCA8dGU\n",
       "coV7pMfcbV/n9X+szBTJts7IeDlJw9L9oeVGXP3uXTgmtlAMYE3f9Kf0ulwLTSWQ46gak3o01pB9\n",
       "moMLrX8gMoyMFWXIcrAGcaMINtyMYSPYttkfqTB1BovQCPaI5wy+8PytRhlJacCx9OOv/X5iC0Jn\n",
       "Me88toIU8QD27aZ8ROVmooecml6KCCfCWGDZpznq4grGxb+sqhatbDyKva0YmvcbQxeCo0Rjzt11\n",
       "mryWwnUuFoe4nfZW4CcvladSVgAz9FymRtPdmAxK7XPrP/sYcRgVjC8jfA8uTowkPm7xv1IzzcLL\n",
       "UISnplpTObuosHzg4t7fh8whUmN23ayhUsIcksYFdudDJf46Y0byh9+L2/cU/DTaUDlewukddR4o\n",
       "XSXRmSYt/eOORFwx0Cr+2ETkrsBPJilIG7qiVSUxwSxfzyyW3glr0fqQfKclNfmXjqH0qUERKfQy\n",
       "ICe7bkbQiFrHqJuv4EFpnxTqj5RtGWJx4IQOZpaCXy1s5UIxhZA3R/kga4biw+EkZjorfLbEbZuK\n",
       "PdLHmQnUYgfOCo8C2lEqeISuK3357EXzU8t6FAyhZ2rijrYh5/dn157wQy8L/NrSMz9td/mDODTA\n",
       "HMJMXpJoAw63MD4jXI/fIXqU8s5Uid7XNpA4MxbE3JJc4R8EOwpLOF2IHSzCOeJdMvpyBf74NOOJ\n",
       "BXQ7+f+coEqZDU5RLeK+Szlndzn1qRsWaI5CLoAAAAM7AZ9wdEN/AVejtVvY9Ojd03V7ONb6+OJe\n",
       "6gGyvZGfDF5Fn+x6xky+ZrRtC7HABBWqbmyEV3YBSsaMVyTIT/9vCYohoZdnr5IxtSRTKcDaNjit\n",
       "Ngif32dM3nKrzH5kDC6jrZSXyDNyStWHH2eFMrvDxU9w2TMxc1VDI5VejMuRKlM+5YWg5ZAlvDDh\n",
       "VMZJpceWaS0sSawAMteGhjYoRJSIc4/77fUg9gT3eP2Qf6zU2FSBLQtC9OIJdckzxzSVa2rJs6D4\n",
       "To2cfrOgzMUO6uQqdSPOLekp+ROKOJD4wDEYJ4Yyv6NT1Thm2LyTYjkdMKulpW6FYsICHxGfaSag\n",
       "KcCUnDNwl74m7Scg/ZO2xTtSRSRTH38K/rKOrjGBihTQXpvnu3ptfqmSG/x8uDUFZdHz8/wtqWUl\n",
       "l0oQRbXcXE5l4XXGsUIU96d+egQmBL8cXmoXOyjUgpEkLyDBkzRXFn1WetsmhCrDi6r/RD0Jk+LK\n",
       "NbImLZTrvRcCHQr3qYRpueNdN35UdBTKOVYRSvufG42pnZC/UcUTx+BUb11LuM5TlltFZC8aXNKh\n",
       "VAo1Rwhkexl6bLjdBMGO6FM71OmHY5ZIoEBiY2LhWAYIbeKhDXDKarlFqOTmJT3HaK7ZiFWcPKMa\n",
       "tL8gA3zmYgUcl9q8TNO1DhdahBKhbDK3frnjBT5+lzjGX7ycixgRAvRKr5BYEiQl09vmTfmOnuFW\n",
       "DDYKUm6cVfarm+VBwEL4pGKGN9OWXVL3Zuwb0q8GKdJigt5/rfZYVXxPa3vSkTLBrONa4q7BhuZl\n",
       "hYT0rm33lrRk0+0+Hg93zLloADchG2HXN4JtxawN+UgaIpKiUVaFJdq/QAdnzrDpouBFl7HZa+fe\n",
       "8qA4mDl/W11iHEZOWF9LN5oXnr2Ci72jL/IyOTLwvYrZMKHDJdiuODeGa3mEddBNXYTsZBLH6b8I\n",
       "E/scIF7RlJ99+RJgvgwR/kKmR93SAtAueT5fadn+Ldbg4A+tvhYTwJNs70vnnSkGYvnKaVmznTWB\n",
       "07tMTQCvXtI5uQINC3DEvzpCQDGfqMzauMFbf4ogCs37OPEm1woAsmKDdo7z9uHES4Ix56f9ixS4\n",
       "IxpnlZUAAAD/AZ9yakN/AVetanftwM4pGZ27jpBNn8AHeLRBu3aA9Q7VIMRXy6Jk7OlStoyzRVps\n",
       "wfgdelVu9KfvP4C+Hs+j9z37T5ohSOdOJ9+ZYat5l9vR82XngWkP/jCeKzOJCYuRtxww89yHG2wW\n",
       "GClFNb7+ObGe50KhtMEln3r7dZGd8Y57xrSVZO94gGQlQAt7FKN7RE5Z1Gu4fpTzcsRIj48R2CBq\n",
       "5XaC7sGTpJCR6H5J6MtCQJCxtY82bxMuOhEAl3dVQlFwLBnZdnky0X1CCbaosYqZLZSXu7QcOPcv\n",
       "6XOJU1y1PEu32iz/IbE/KlVzmxDOqZedZdzdfgbupdnimqKeAAACMkGbdUmoQWyZTBRMP//+qZYI\n",
       "XulM5Em+TSXTqF+1PX3ItaBH36n1GJzx+DrtGAFQVkWzgFpXUC+JabnIgQNlCxw+W9TWJZNhN1ST\n",
       "SZJ2h01MxxSQruPGEOYnT9xenvOreN6I4VJ2nig8QevrS6sjZxLp9wekIL4Dxp1fW4npcrjhZfVi\n",
       "lytRz6AzW1SoUNdefeZGQQ+D0oLTzhyUaDZiePc7tiCmc8/Hf7lH3wFsyf+IzlNeel8oo5Z5twNi\n",
       "EfTIR8+w6gnAgMrp1V7DaQXDYjHo5rNYJy1CY++KsFkAalQuNIwnORuWtCjWZwrwZuEkHy1/R1cT\n",
       "ASFKh3rjn+unYa9n+M3qKS/jWdelzuyTm1mo38QPyZiu4xxkXwhh0y/m7Catefz+k4+crr+IlPYO\n",
       "osOakcZ8Ab3klUjByv5K1tJEVlsecGU3flHSEfeiwcVnM3jED0RDVs+EC+WvgDp5U+tyUMxyMPyL\n",
       "333do66qmkEQvnx9p3OMlN7ZlM7jeM6+CTSGRxFXE3v+D/DlToQz+p+qhWi7xQYOgOweL9zQkJvy\n",
       "Z1h0uMAE1Oy9yVNVeD9mYkmyfL+143ujh2cGwle09Dvynmnlfr/5G7LycLbUrcp3kP7lAyiJvcxh\n",
       "A9Q+oABqk4eg4Zjsq610asSPIGPQxeSulYR8qLNbfWHL1eCmvKnpGatOI16/XjDjqwOuuA1yz4o6\n",
       "miXENz4jwFbWfdqxI+1rVBmuOGOD1gAyYsx+LSmErGAAAABGAZ+UakN/AOcAx65XcxRTbqfuSJTB\n",
       "OobX2RjFQAJYqLgXmGcryGY3XIOFKDbyf6F2QLFQq8GxbyizquL50c6fnYzqL30aUQAAAUpBm5ZJ\n",
       "4QpSZTAh//6plgCsfGggCe1rVr6WV77kigCnBbzYvyPoTxoTYPmJtpynQj02XcSWfTKI1DC0xnuQ\n",
       "bos6alOYTc6Nfm4V5BP9hx3DR3NgyNQoA1tD+GMHYnI+HPsd/NMijV13nEOTXED2ucmCww6Wf2l3\n",
       "dNNUkW+aMq9WFyPZiDrV5tXHMHLboypufTDZ2D12qbWUMuo9lLq3Kmz2IK8KzZo1xdMs5lYuxtUj\n",
       "A0ccvXxnJ/+Y2Wafw+J+g3yUCBz5D2JzBf854u5IpXJ8aC2pZgR61JoqfwZgV7QyzZgEWvmp5GpW\n",
       "BSwV4hRspkGlOBSH8teupIeqZLJMpNpiZHu8Cl+rwUPb3N7N5WhmKKV7grheVrtQzSCaCWTBZi/y\n",
       "VSf6Y5RRE2KnJXEi7BQlgpuL7g2u+JuMgxuuCOFynVEpDRmA9O6eC/gAAAGwQZu3SeEOiZTAgh/+\n",
       "qlUAGesa/30AONAlgK4knxUBrFlEYINNieOZLVxy7bblbBY38MKRPEAYKIdoF9mgm/PVKNPeRPvD\n",
       "cDFFHGout0W6lX3ZcbMjzIzBp1WQeQzP/Mcv+dvz8ts81zKS4TDvOl3u+K8SBYf9ARsgylDP6+rp\n",
       "o3TTLC7OJgttFRPUnlT7G9TK68NUprh+0EAFW8jgTgU/Sza1wln7VRUBcl7++f6U+LbBO+V8pWM0\n",
       "l3z4yCtp+Nzd3vOvdqBzzx2iugaQYOJZqCBQQVWy0LgEVzHIUH/mieRpuryzd0fGnnL7VWozXRTG\n",
       "ZC0GZ/qa8U3aaCS+CI7rdlWe9lqcFm/lDWtOZpmBgINKXaL1QOoOtP6ZEKdTwbMZ05r8QXuRMfm2\n",
       "J5KlOFg8zky5lcMkMpgR7Tffa/wri/LPKgyIBL7FB9CDKxYUkRgQq+paNwwcUyVFmYTy1qK47PEB\n",
       "PSJL5QJpiRY4KB40bMiL4cDjhtqnJPmPsoHd3bf16Ai/TS1xK7ipEruZiygkPifBgAzGL2pvXRHx\n",
       "6nZlgRWEfL2wonIOT9g4z6DcBOLhAAABkEGb2UnhDyZTBRE8P//+qZYAvAYMCgevLsYmaAdykGX3\n",
       "pbz44pT18oXX7PVUcINjPYHSUcpZidUWnzK8TIXszkrWkRZmvihUAsZjrIX5PClgdNh/7V4jfcRx\n",
       "eWB8y1kt9d3d8Ry7XOYuEubp5Gl+X+7Rx4H3lyg0ptR+ac4rDw3Udt94rNXoO2ryCAKGGVHv7QSF\n",
       "TSdnMzpQxKHaMbvkH1IbkiM1A/ziAu1lj+CGFuF8Xx7WKctuuJ9mRR9RNdFp/72XD/OLgmhyswJZ\n",
       "7EO5TlMGmOy/9pNwtZMOAelSED9YgPX/Hu+auUTeqWwYKlN9wLidwVIZwy0ycxKMJQ9gojsfg5lf\n",
       "l1abkTrdkbbaBKewbXcHzrFa7KUkYhtgYWIXHopzUR3CPS8fx9uHeofA2SEnzgcrkvBC2BsIacsm\n",
       "BQVQIr9PSev9ZcWexkVMtyQJOMQ7w0W4PabzidKoIvwtXnQw0a7MIACPCX3YFXxJt/1dbne6Ri3u\n",
       "9jbvK8y0yfcPSBbuhlxHgELGYP9knNJAAUsAAAA1AZ/4akN/AOcAx772dBeNU2mspFDhQin9EZrq\n",
       "x3kv5viB2FbxO860fxfFWFIqA19owgbxX/MAAACqQZv6SeEPJlMCH//+qZYAZSqTc+IAhhEK021q\n",
       "tuvHDAQW16Igiol84t5+9Lxrm3wjuoVyNKBMP9uKrNstzvFhv+Yg3vXpofyy2SUhz6tCQ6jyu3mC\n",
       "Mqpabh1RN1IRL/vSWfyaRgDmsP9978WorSVN7+yShwGeMNPfAIjdPWtsJs4nJyp3nWCz0UF5rbrV\n",
       "1772MlRsqJjE6r1OyEJw+te9oYn78JoVOe9WG4EAAAQhQZodSeEPJlMCG//+p4QBkJexPSiAFjc1\n",
       "1WCT4J7JCnuc3iOoU4QY3rrXhgo1s3rOQbDs6rXqHoykV6uYxuXteM/W/5Od2EvIgHdtiUkoa/RK\n",
       "5x82egkLkgeqtfx2rnK+XQxBW23gJoktNtnzqdmrQEfugUTg+gvxTfCGgCfY5P9yI8frKoeJ5LnK\n",
       "vkvRNk24g5pfCs9TxcTFqigHmS5NO7zC8MImGIHAKujESjNh+qYKEsedj5RTPOYSLorLmnJdrZvx\n",
       "xMnJbuR0ZE6F9c1cOsPE15haXZTDv1YYWW6KZa5IocptKWao9MR+yH6kCHrEpl5vv5i4Php67weg\n",
       "je3yU9AGBRw3jK9/D6nsq/jYhrHfXlJaQLw85Zn4qrdrbrbuqo6smmAer28WfOl8ICAJyjKsbx8Z\n",
       "T1997jsFfsBr4elw62MYwGIe0Tnj87bipXyKXN1pwoFyfvPWq7iwpa3iSPjXIcPbIxK3v/D3KNKe\n",
       "Ohtu/hn2fmk06VlcHfwVwGTIUv4us8yZMpAfKzoINTUS1z8y4IPmjVgwXs9k9MzUTBL1usNyBbHB\n",
       "o6bZ+NnOdj73c39hK2cQRYoiTgBQRJYPiDdzooGZ51vIhJGpK63IYf/Cd+AUN1vqbGa9klMBc7fa\n",
       "rDNznjhXDTbjTx6RwZQOqgMn4Y8bBfzFNRHNB5kaQSGG9t7qQJXt9PmiscpOYzIdAmJu8HmuMajg\n",
       "AYqq1V6rKG3XGMzrPeDAzDQ4tIUwlasUSyj64EUD4/El/aaReH7tr7hKjsiNLPlT74BV/2ZUHkpb\n",
       "QSFCj5qLTt04Qb1xO/7Uq92KjxZ/9XHmHBDB0nSAoMJpWnxCWF5k1GSH3qVkLdj7E8ZjhaHYexBs\n",
       "58Unts3tFWSWNl646lKFDAq80AXaPOFAMVK37wAgjLbr1ILULd7swUQD07bGrwrolhGFh2i98S6c\n",
       "OiOjAiHRd/jRsmOUN4Hmo5hG2rsrsIhqVEdqKGJnYLlfaqOlYdis16e5wlE3bqGkfHwNoByB9fmL\n",
       "uIPsPsOOk+mD2ihoWytI309mKAfA61/6X356EvfjbFQHhXPL/XSOPmt/PMcDmO0MkY04pg0wqvm8\n",
       "dKbM1vn/hmsdTlsb2myBXVblYhKSKLh/tciZhP4UGQDCxPL1mraVaGKB+Ups7ATZzpIRiNzsKuqB\n",
       "MkFOnkPVEpVfjeaYnPEgy3TCOCt6xivMFRkNdgALP8Xc69oApbphR6/hBHIiEh2RYs46XaJ0cEjw\n",
       "UXZKXrePWRs7goIvXl/Z/WhSxV80AdVBpTCEXBctCCj69Y9j8PHD7qx+NvuMPtseHUGPouqH5NpE\n",
       "B+eDyJridyXnuQQKRhNZqrBT+zuUaUzErSh432sC19XA7lsHZ6iz+Unav9bywUFDXhmEENdzDhb3\n",
       "nSOyyuQYrwAAANxBnjtFETw3/wDnAMg4V9GtXVYXhoOSuJHX031L93ZszBpTMQutcPZ9QmDzcYqN\n",
       "VvOeleZKfcoGibPMR9mWWiXPo8gpxmMOTXxFCqBPZlnwl21emfYXfvB3/Z1VMUrRbRv2/OIMh/7K\n",
       "AGMmFvQwqqJmREFUizRQPuvnXBryJM/tY1+nc0eylMcwOEURsY8C3mm9VI+8kD1cm01+3797ww49\n",
       "DPI3np1pupJUXVItUJ8U6ESdZc8UnnQbaUAP7LOAGutX1zabEfUuGMWjn73Ng8Y3p1rmE75MPmyI\n",
       "g9IHAAAASAGeXGpDfwB2ihAnAV33t1t4TmEB4beGQvHqk3XSrbZPpULdmZD21p1Hu2ae8YWeFrDf\n",
       "oCerXmqnSCreG6c30arN04aqOjHzdQAABH5tb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAL\n",
       "uAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAADqHRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEA\n",
       "AAAAAAALuAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAA\n",
       "AAABsAAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAC7gAAAgAAAEAAAAAAyBtZGlhAAAA\n",
       "IG1kaGQAAAAAAAAAAAAAAAAAACgAAAB4AFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAA\n",
       "AAAAAFZpZGVvSGFuZGxlcgAAAALLbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAc\n",
       "ZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAACi3N0YmwAAACzc3RzZAAAAAAAAAABAAAAo2F2YzEA\n",
       "AAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABsAEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFkABX/4QAYZ2QAFazZQbCWhAAAAwAEAAADAFA8\n",
       "WLZYAQAGaOvjyyLAAAAAHHV1aWRraEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEA\n",
       "AAAeAAAEAAAAABRzdHNzAAAAAAAAAAEAAAABAAAA6GN0dHMAAAAAAAAAGwAAAAEAAAgAAAAAAQAA\n",
       "FAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAE\n",
       "AAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAEAAAAAACAAAEAAAAAAEAABQA\n",
       "AAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAADAAAAAABAAAEAAAAAAIAAAgAAAAAAQAADAAA\n",
       "AAABAAAEAAAAAAEAAAgAAAAAAQAAEAAAAAACAAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAHgAA\n",
       "AAEAAACMc3RzegAAAAAAAAAAAAAAHgAAEJMAAAb4AAACgwAAAZ0AAAGZAAAHIwAAAmMAAAH7AAAB\n",
       "swAABqQAAAHRAAABoQAAAWEAAAVNAAABuwAAAe8AAAebAAACPwAAAz8AAAEDAAACNgAAAEoAAAFO\n",
       "AAABtAAAAZQAAAA5AAAArgAABCUAAADgAAAATAAAABRzdGNvAAAAAAAAAAEAAAAsAAAAYnVkdGEA\n",
       "AABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWp\n",
       "dG9vAAAAHWRhdGEAAAABAAAAAExhdmY1OC4yMC4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = videos[0]\n",
    "final_video = video.numpy()\n",
    "\n",
    "for i in range(15):\n",
    "    frame = downstream_model.predict(tf.expand_dims(video, axis=0))\n",
    "    final_video = np.concatenate([final_video, frame], axis=0)\n",
    "    frame = tf.convert_to_tensor(frame)\n",
    "    video = tf.concat([video, frame], 0)\n",
    "    video = video[1:, ...]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "big_im = ax.imshow(final_video[0, :, :], cmap='gray')\n",
    "ax.set_axis_off()\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    big_im.set_data(final_video[0,:,:])\n",
    "def animate(j):\n",
    "    big_im.set_data(final_video[j,:,:])\n",
    "anim = animation.FuncAnimation(\n",
    "    fig,\n",
    "    animate,\n",
    "    init_func=init,\n",
    "    frames=final_video.shape[0],\n",
    "    interval=100\n",
    ")\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb4ee5-0131-4500-a5ed-9daa1d9ebdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
